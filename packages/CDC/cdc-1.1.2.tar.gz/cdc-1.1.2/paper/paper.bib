@Article{matese2015,
AUTHOR = {Matese, Alessandro and Toscano, Piero and Di Gennaro, Salvatore Filippo and Genesio, Lorenzo and Vaccari, Francesco Primo and Primicerio, Jacopo and Belli, Claudio and Zaldei, Alessandro and Bianconi, Roberto and Gioli, Beniamino},
TITLE = {Intercomparison of UAV, Aircraft and Satellite Remote Sensing Platforms for Precision Viticulture},
JOURNAL = {Remote Sensing},
VOLUME = {7},
YEAR = {2015},
NUMBER = {3},
PAGES = {2971--2990},
URL = {https://www.mdpi.com/2072-4292/7/3/2971},
ISSN = {2072-4292},
ABSTRACT = {Precision Viticulture is experiencing substantial growth thanks to the availability of improved and cost-effective instruments and methodologies for data acquisition and analysis, such as Unmanned Aerial Vehicles (UAV), that demonstrated to compete with traditional acquisition platforms, such as satellite and aircraft, due to low operational costs, high operational flexibility and high spatial resolution of imagery. In order to optimize the use of these technologies for precision viticulture, their technical, scientific and economic performances need to be assessed. The aim of this work is to compare NDVI surveys performed with UAV, aircraft and satellite, to assess the capability of each platform to represent the intra-vineyard vegetation spatial variability. NDVI images of two Italian vineyards were acquired simultaneously from different multi-spectral sensors onboard the three platforms, and a spatial statistical framework was used to assess their degree of similarity. Moreover, the pros and cons of each technique were also assessed performing a cost analysis as a function of the scale of application. Results indicate that the different platforms provide comparable results in vineyards characterized by coarse vegetation gradients and large vegetation clusters. On the contrary, in more heterogeneous vineyards, low-resolution images fail in representing part of the intra-vineyard variability. The cost analysis showed that the adoption of UAV platform is advantageous for small areas and that a break-even point exists above five hectares; above such threshold, airborne and then satellite have lower imagery cost.},
DOI = {10.3390/rs70302971}
}

@article{pareview2020,
title = {A compilation of UAV applications for precision agriculture},
journal = {Computer Networks},
volume = {172},
pages = {107148},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107148},
url = {https://www.sciencedirect.com/science/article/pii/S138912862030116X},
author = {Panagiotis Radoglou-Grammatikis and Panagiotis Sarigiannidis and Thomas Lagkas and Ioannis Moscholios},
keywords = {Precision agriculture (PA), Remote sensing (RS), Unmanned aerial vehicle (UAV)},
abstract = {Climate change has introduced significant challenges that can affect multiple sectors, including the agricultural one. In particular, according to the Food and Agriculture Organization of the United Nations (FAO) and the International Telecommunication Union (ITU), the world population has to find new solutions to increase the food production by 70% by 2050. The answer to this crucial challenge is the suitable adoption and utilisation of the Information and Communications Technology (ICT) services, offering capabilities that can increase the productivity of the agrochemical products, such as pesticides and fertilisers and at the same time, they should minimise the functional cost. More detailed, the advent of the Internet of Things (IoT) and specifically, the rapid evolution of the Unmanned Aerial Vehicles (UAVs) and Wireless Sensor Networks (WSNs) can lead to valuable and at the same time economic Precision Agriculture (PA) applications, such as aerial crop monitoring and smart spraying tasks. In this paper, we provide a survey regarding the potential use of UAVs in PA, focusing on 20 relevant applications. More specifically, first, we provide a detailed overview of PA, by describing its various aspects and technologies, such as soil mapping and production mapping as well as the role of the Global Positioning Systems (GPS) and Geographical Information Systems (GIS). Then, we discriminate and analyse the various types of UAVs based on their technical characteristics and payload. Finally, we investigate in detail 20 UAV applications that are devoted to either aerial crop monitoring processes or spraying tasks. For each application, we examine the methodology adopted, the proposed UAV architecture, the UAV type, as well as the UAV technical characteristics and payload.}
}

@article{xue2017,
  title={Significant remote sensing vegetation indices: A review of developments and applications},
  author={Xue, Jinru and Su, Baofeng},
  journal={Journal of sensors},
  volume={2017},
  number={1},
  pages={1353691},
  year={2017},
  publisher={Wiley Online Library}
}

@article{PANG2020,
title = {Improved crop row detection with deep neural network for early-season maize stand count in UAV imagery},
journal = {Computers and Electronics in Agriculture},
volume = {178},
pages = {105766},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105766},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920311376},
author = {Yan Pang and Yeyin Shi and Shancheng Gao and Feng Jiang and Arun-Narenthiran Veeranampalayam-Sivakumar and Laura Thompson and Joe Luck and Chao Liu},
keywords = {Plant population, Deep learning, RCNN, Remote sensing, UAS},
abstract = {Stand counts is one of the most common ways farmers assess plant growth conditions and management practices throughout the season. The conventional method for early-season stand count is through manual inspection, which is time-consuming, laborious, and spatially limited in scope. In recent years, Unmanned Aerial Vehicles (UAV) based remote sensing has been widely used in agriculture to provide low-altitude, high spatial resolution imagery to assist decision making. In this project, we designed a system that uses geometric descriptor information with deep neural networks to determine early-season maize stands from relatively low spatial resolution (10 to 25 mm) aerial data, which covers a relatively large area (10 to 25 hectares). Instead of detecting individual crops in a row, we process the entire row at one time, which significantly reduces the requirements for the clarity of the crops. Besides, our new MaxArea Mask Scoring RCNN algorithm could segment crop-rows out in each patch image, regardless of the terrain conditions. The robustness of our scheme was tested on data collected at two different fields in different years. The accuracy of the estimated emergence rate reached up to 95.8%. Due to the high processing speed of the system, it has the potential for real-time applications in the future.}
}

@Article{midtiby2022,
AUTHOR = {Midtiby, Henrik Skov and Pastucha, Elżbieta},
TITLE = {Pumpkin Yield Estimation Using Images from a UAV},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {4},
ARTICLE-NUMBER = {964},
URL = {https://www.mdpi.com/2073-4395/12/4/964},
ISSN = {2073-4395},
ABSTRACT = {The paper presents a pumpkin yield estimation method using images acquired by a UAV. The processing pipeline is fully automated. It consists of orthomosaic generation, a color model collection using a random subset of the data, color segmentation, and finally counting of pumpkin blobs together with assessing the number of pumpkins in each blob. The algorithm was validated by a manual check of 5% of each tested dataset. The precision value ranges between 0.959 and 0.996, recall between 0.971 and 0.987, and F1 score falls between 0.971 and 0.988. This proves the very high efficiency of the processing workflow and its potential value to farmers.},
DOI = {10.3390/agronomy12040964}
}


@InProceedings{Ronneberger2015Unet,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

@article{Woebbecke1995,
   abstract = {Color slide images of weeds among various soils and residues were
digitized and analyzed for red, green, and blue (RGB) color content.
Red, gree, and blue chromatic coordinates (rgb) of plants were very
different from those of background soils and residue. To distinguish
living plant material from a nonplant background, several indices
of chromatic coordinates were studied, tested, and were successful
in identifying weeds. The indices included r-g, g-b, (g-b)/|r-g|,
and 2g-r-b. A modified hue was also used to distinguish weeds from
non-plant surfaces. The modified hue, 2g-r-b index, and the other
indices. however, the modified hue was the most computationally intense.
These indices worked well for both nonshaded and shaded sunlit conditions.
These indices could be used for sensor design for detecting weeds
for spot spraying control},
   author = {D. M. Woebbecke and G. E. Meyer and K. Von Bargen and D. A. Mortensen},
   doi = {10.13031/2013.27838},
   issn = {2151-0059},
   issue = {1},
   journal = {Transactions of the ASAE},
   keywords = {color,indices,machinevision},
   pages = {259-269},
   title = {Color Indices for Weed Identification Under Various Soil, Residue, and Lighting Conditions},
   volume = {38},
   url = {http://elibrary.asabe.org/abstract.asp??JID=3&AID=27838&CID=t1995&v=38&i=1&T=1},
   year = {1995}
}

@article{scikit-learn,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}

@misc{ MahalanobisDistance,
   author = "{Wikipedia contributors}",
   title = "Mahalanobis distance --- {Wikipedia}{,} The Free Encyclopedia",
   year = "2025",
   url = "https://en.wikipedia.org/w/index.php?title=Mahalanobis_distance&oldid=1285312885",
   note = "[Online; accessed 24-April-2025]"
}
