# pylint: disable=too-many-lines
# coding=utf-8
# --------------------------------------------------------------------------
# Code generated by Microsoft (R) AutoRest Code Generator (autorest: 3.10.3, generator: @autorest/python@6.26.7)
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------

from enum import Enum
from azure.core import CaseInsensitiveEnumMeta


class AbbreviationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Numeric formatting and abbreviation type."""

    RAW = "raw"
    SI = "si"
    DOLLAR = "dollar"
    DOLLAR_RAW = "dollar-raw"
    BYTE = "byte"
    BYTE_DECIMAL = "byte-decimal"
    BYTE_IEC = "byte-iec"
    BIT_PER_SECOND = "bit-per-second"
    BIT_PER_SECOND_DECIMAL = "bit-per-second-decimal"
    BIT_PER_SECOND_IEC = "bit-per-second-iec"
    PERCENT = "percent"
    PERCENT_RAW = "percent-raw"
    MILLISECOND = "millisecond"
    MICROSECOND = "microsecond"
    NANOSECOND = "nanosecond"
    MILLIWATT = "milliwatt"
    SECONDS_AS_TIME = "seconds-as-time"
    DURATION = "duration"
    DURATION_AGO = "duration-ago"
    TIME_FORMAT = "time-format"


class AbsoluteCompareType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """AbsoluteCompareType."""

    ABSOLUTE = "absolute"


class AggregateTableColumnType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The column type for an aggregate table:


    * ``dimension`` - Columns that are stored as is. These columns are used as the grouping keys
    for aggregation.
    * ``measure``   - Columns that are aggregated during ingestion.
    """

    DIMENSION = "dimension"
    MEASURE = "measure"


class AggregateTableMeasureColumnDataType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The expected data type of an aggregate table measure column."""

    BIGINT = "bigint"
    DOUBLE = "double"
    FLOAT = "float"
    HLL_SKETCH = "HLLSketch"
    LONG = "long"
    LONG_STRING_PAIR = "longStringPair"
    QUANTILES_DOUBLES_SKETCH = "quantilesDoublesSketch"
    STRING = "string"
    THETA_SKETCH = "thetaSketch"
    INGEST_TIMESERIES = "ingest_timeseries"
    VARCHAR = "varchar"
    VARIANCE = "variance"


class AlertConditionOperator(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Specify ``lessThan`` to trigger the alert when the measure value is less than the specified
    value, or ``greaterThan`` to trigger the alert when the measure value is greater than the
    specified value.
    """

    LESS_THAN = "lessThan"
    GREATER_THAN = "greaterThan"


class AlertConditionType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Specify ``value`` to evaluate against an absolute value, ``delta`` to evaluate against the
    change in absolute value, or ``percent-delta`` to evaluate against the percentage change
    in the measure value.
    """

    VALUE = "value"
    DELTA = "delta"
    PERCENT_DELTA = "percent-delta"


class AlertEvaluationErrorType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of error that occurred during alert evaluation."""

    INTERNAL_ERROR = "internal-error"
    WEBHOOK_ERROR = "webhook-error"
    EMAIL_ERROR = "email-error"
    MISCONFIGURATION_ERROR = "misconfiguration-error"


class AlertType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Specify ``overall`` to evaluate against a measure, and ``within-split`` to evaluate against a
    dimension.
    """

    OVERALL = "overall"
    WITHIN_SPLIT = "within-split"


class AllAccessListAccess(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """AllAccessListAccess."""

    ALL = "all"


class AuditEventActorType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of user that triggered the audit event."""

    UNKNOWN = "unknown"
    APIKEY = "apikey"
    USER = "user"
    IMPLY_ADMIN = "imply-admin"


class AuditEventCategory(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Category of the audit event."""

    AUTH = "AUTH"
    ADMIN = "ADMIN"


class AuditEventType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of the audit event."""

    IMPERSONATED = "IMPERSONATED"
    LOGIN = "LOGIN"
    LOGIN_FAILED = "LOGIN_FAILED"
    LOGOUT = "LOGOUT"
    PASSWORD_RESET_REQUESTED = "PASSWORD_RESET_REQUESTED"
    PASSWORD_UPDATED = "PASSWORD_UPDATED"
    USER_INVITE_ACCEPTED = "USER_INVITE_ACCEPTED"
    APIKEY_CREATED = "APIKEY_CREATED"
    APIKEY_DELETED = "APIKEY_DELETED"
    APIKEY_NAME_UPDATED = "APIKEY_NAME_UPDATED"
    APIKEY_DESCRIPTION_UPDATED = "APIKEY_DESCRIPTION_UPDATED"
    APIKEY_PERMISSIONS_ADDED = "APIKEY_PERMISSIONS_ADDED"
    APIKEY_PERMISSIONS_REMOVED = "APIKEY_PERMISSIONS_REMOVED"
    APIKEY_SCOPE_ALL_PROJECTS = "APIKEY_SCOPE_ALL_PROJECTS"
    APIKEY_SCOPE_SPECIFIC_PROJECTS = "APIKEY_SCOPE_SPECIFIC_PROJECTS"
    APIKEY_UPDATED = "APIKEY_UPDATED"
    GROUP_CREATED = "GROUP_CREATED"
    GROUP_DELETED = "GROUP_DELETED"
    GROUP_MEMBER_ADDED = "GROUP_MEMBER_ADDED"
    GROUP_MEMBER_REMOVED = "GROUP_MEMBER_REMOVED"
    GROUP_NAME_CHANGED = "GROUP_NAME_CHANGED"
    GROUP_PERMISSIONS_ADDED = "GROUP_PERMISSIONS_ADDED"
    GROUP_PERMISSIONS_REMOVED = "GROUP_PERMISSIONS_REMOVED"
    GROUP_SCOPE_ALL_PROJECTS = "GROUP_SCOPE_ALL_PROJECTS"
    GROUP_SCOPE_SPECIFIC_PROJECTS = "GROUP_SCOPE_SPECIFIC_PROJECTS"
    GROUP_UPDATED = "GROUP_UPDATED"
    USER_CREATED = "USER_CREATED"
    USER_DELETED = "USER_DELETED"
    USER_DISABLED = "USER_DISABLED"
    USER_ENABLED = "USER_ENABLED"
    USER_INVITE_SENT = "USER_INVITE_SENT"
    USER_NAME_CHANGED = "USER_NAME_CHANGED"
    USER_PASSWORD_RESET = "USER_PASSWORD_RESET"
    USER_GROUPS_ADDED = "USER_GROUPS_ADDED"
    USER_GROUPS_REMOVED = "USER_GROUPS_REMOVED"
    USER_UPDATED = "USER_UPDATED"


class BooleanFilterOperator(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """BooleanFilterOperator."""

    EQ = "eq"


class BooleanFilterType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """BooleanFilterType."""

    BOOLEAN = "boolean"


class BubbleChartType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    BUBBLE_CHART = "bubble-chart"


class BucketingStrategy(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The bucketing strategy for a dimension."""

    DEFAULT_BUCKET = "defaultBucket"
    DEFAULT_NO_BUCKET = "defaultNoBucket"
    NEVER_BUCKET = "neverBucket"
    ALWAYS_BUCKET = "alwaysBucket"


class CollectionAssetType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Collection asset type."""

    DATA_CUBE = "dataCube"
    DASHBOARD = "dashboard"
    ALERT = "alert"
    REPORT = "report"
    EMBEDDING = "embedding"
    TABLE = "table"
    CONNECTION = "connection"
    FILE = "file"


class CompareType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """CompareType."""

    ABSOLUTE = "absolute"
    RELATIVE = "relative"
    TIME_RELATIVE = "time-relative"
    TIME_ABSOLUTE = "time-absolute"
    UNFILTER = "unfilter"
    FILTER = "filter"
    MEASURE = "measure"


class CompressionFormat(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Compression format:


    * ``bz2`` - bzip2
    * ``gz`` - gzip
    * ``sz`` - `Snappy framing format
    <https://github.com/google/snappy/blob/master/framing_format.txt>`_
    * ``xz`` - XZ Utils (previously LZMA Utils)
    * ``zstd`` - `ZStandard <https://facebook.github.io/zstd/>`_.
    """

    NONE = "none"
    BZ2 = "bz2"
    GZ = "gz"
    SZ = "sz"
    XZ = "xz"
    ZSTD = "zstd"


class ConditionOperation(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Select whether one or all conditions must be true to trigger the alert."""

    AND = "and"
    OR = "or"


class ConnectionSecretsTypePayload(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """ConnectionSecretsTypePayload."""

    ACCESS_KEY = "access_key"
    AWS_IAM = "aws_iam"
    BASIC = "basic"
    CONFLUENT = "confluent"
    SAS_TOKEN = "sas_token"
    SASL_PLAIN = "sasl_plain"
    SASL_SCRAM = "sasl_scram"


class ConnectionTypePayload(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Connection type. For reference on the information required for each connection type, see
    `Create a connection <https://docs.imply.io/polaris/connections>`_.
    """

    AZURE = "azure"
    CONFLUENT = "confluent"
    CONFLUENT_SCHEMA_REGISTRY = "confluent_schema_registry"
    KAFKA = "kafka"
    KINESIS = "kinesis"
    PUSH_STREAMING = "push_streaming"
    S3 = "s3"


class DashboardType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Dashboard type - always "dashboard2"."""

    CLASSIC = "classic"
    DASHBOARD2 = "dashboard2"


class DataCubePayloadQueryCaching(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Allow caching on queries made to this data cube. Caching can greatly speed up exploration but
    can
    also cause results to be a little out of date especially in realtime rolled up datasets.
    """

    ALLOW = "allow"
    DISABLE = "disable"


class DataCubeSourceType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Data cube source type."""

    DIRECT = "direct"
    QUERY = "query"


class DataFormat(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Data format:


    * ``avro_ocf`` - Avro OCF (Object Container Format) for batch ingestion
    * ``avro_stream`` - Avro for stream ingestion
    * ``csv`` - Delimiter-separated data including CSV and TSV
    * ``kafka`` - Format to ingest Kafka values in one of the `supported formats
    <https://docs.imply.io/ui/saas/help/supported-formats>`_ as well as event metadata
    * ``kinesis`` - Format to ingest Kinesis values in one of the `supported formats
    <https://docs.imply.io/ui/saas/help/supported-formats>`_ as well as event metadata
    * ``nd-json`` - Newline-delimited JSON (one JSON record per line)
    * ``orc`` - ORC format
    * ``parquet`` - Parquet format
    * ``protobuf`` - Protobuf format
    * ``regex`` - Format to parse using a regular expression.
    """

    AVRO_OCF = "avro_ocf"
    AVRO_STREAM = "avro_stream"
    CSV = "csv"
    KAFKA = "kafka"
    KINESIS = "kinesis"
    ND_JSON = "nd-json"
    ORC = "orc"
    PARQUET = "parquet"
    PROTOBUF = "protobuf"


class DeliveryDayType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """For frequencies that span one month or more, you can choose whether to deliver the report on a
    numbered day of the month (\\ ``of-month``\\ ) or on the first specified weekday of the month
    (\\ ``of-week``\\ ).
    Examples:


    * `dayType`: `of-month` and `day`: ``15`` delivers the report on the 15th day of the month.
    * `dayType`: `of-week` and `day`: 1` delivers the report on the first Monday of the month.
    """

    OF_MONTH = "of-month"
    OF_WEEK = "of-week"


class DeliveryFrequencyType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """A ``fixed`` frequency was chosen from a predefined list in the Polaris UI. A ``custom``
    frequency was entered manually.
    """

    FIXED = "fixed"
    CUSTOM = "custom"


class DesiredJobExecutionStatusV2(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Desired execution status of the job. This field only applies to updating an ingestion job and
    is ignored when creating jobs. You cannot update a deletion job. The default desired execution
    status is ``running`` for jobs that should run to completion. Otherwise, specify the value
    ``canceled`` to cancel an ingestion job. If an unsupported value is supplied, Polaris raises a
    ``400 Bad Request`` error.
    """

    RUNNING = "running"
    CANCELED = "canceled"
    SUSPENDED = "suspended"


class DigestAlgo(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The algorithm used to hash the file's content."""

    MD5 = "md5"


class DimensionOthers(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Displays an "Other" row showing sum total of the measure for all the dimension values that were
    cut off by the limit.
    """

    AUTO = "auto"
    HIDE = "hide"
    SHOW = "show"


class DimensionOverall(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Displays an "Overall" row showing the sum total of the chosen measure."""

    AUTO = "auto"
    HIDE = "hide"
    SHOW = "show"


class DimensionType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Specific data type for a dimension. For IP Prefix dimensions, use the ``IP`` data type
    and set ``ipPrefix``\\ : ``true`` on the dimension.
    """

    TIME = "TIME"
    STRING = "STRING"
    SET_STRING = "SET/STRING"
    NUMBER = "NUMBER"
    BOOLEAN = "BOOLEAN"
    IP = "IP"
    TIME_SERIES = "TIME_SERIES"


class EmbeddedBubbleChartVisualizationType(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """Name of the visualization."""

    BUBBLE_CHART = "bubble-chart"


class EmbeddedGeoMarksVisualizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    GEO_MARKS = "geo-marks"


class EmbeddedGeoShadeVisualizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    GEO_SHADE = "geo-shade"


class EmbeddedHeatMapVisualizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    HEATMAP = "heatmap"


class EmbeddedHorizontalBarsVisualizationType(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """Name of the visualization."""

    HORIZONTAL_BARS = "horizontal-bars"


class EmbeddedLineChartVisualizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Visualization type."""

    LINE_CHART = "line-chart"


class EmbeddedPathTreeVisualizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    PATH_TREE = "path-tree"


class EmbeddedPieChartVisualizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    PIE_CHART = "pie-chart"


class EmbeddedRawVisualizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    RAW = "raw"


class EmbeddedSankeyVisualizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    SANKEY = "sankey"


class EmbeddedSparkLineVisualizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    SPARK_LINE = "spark-line"


class EmbeddedSpotMatrixVisualizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    SPOT_MATRIX = "spot-matrix"


class EmbeddedStackAreaChartVisualizationType(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """Name of the visualization."""

    STACK_AREA_CHART = "stack-area-chart"


class EmbeddedSunburstVisualizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    SUNBURST = "sunburst"


class EmbeddedTableVisualizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Visualization type."""

    TABLE = "table"


class EmbeddedTotalsVisualizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    TOTALS = "totals"


class EmbeddedTreeMapVisualizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    TREEMAP = "treemap"


class EmbeddedVerticalBarsVisualizationType(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """Visualization type."""

    VERTICAL_BARS = "vertical-bars"


class EmbeddingBarChartLegendPosition(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Specify the position of the legend. If undefined the legend displays in the top position."""

    TOP = "top"
    BOTTOM = "bottom"
    LEFT = "left"
    RIGHT = "right"
    NONE = "none"


class EmbeddingBarChartModuleName(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """EmbeddingBarChartModuleName."""

    BAR_CHART = "bar_chart"


class EmbeddingBarChartXAxisCustomizationLabelOrientation(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """Orientation of the x-axis labels."""

    HORIZONTAL = "horizontal"
    AUTO = "auto"
    ANGLED = "angled"


class EmbeddingBooleanFilterType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """EmbeddingBooleanFilterType."""

    BOOLEAN = "boolean"


class EmbeddingDimensionOthers(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Displays an "Other" row showing sum total of the measure for all the dimension values that were
    cut off by the limit.
    """

    AUTO = "auto"
    HIDE = "hide"
    SHOW = "show"


class EmbeddingDimensionOverall(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Displays an "Overall" row showing the sum total of the chosen measure."""

    AUTO = "auto"
    HIDE = "hide"
    SHOW = "show"


class EmbeddingFlatTableParametersDisplayYear(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """Whether to display the year in time values."""

    AUTO = "auto"
    ALWAYS = "always"
    NEVER = "never"


class EmbeddingFlatTableParametersModuleName(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """Visualization type."""

    FLAT_TABLE = "flat_table"


class EmbeddingFlatTableParametersMultipleValueMode(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """How to display data for columns with multiple values."""

    NULL = "None"
    LATEST = "latest"
    LATEST_NON_NULL = "latestNonNull"
    COUNT = "count"


class EmbeddingGaugeParametersModuleName(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """EmbeddingGaugeParametersModuleName."""

    GAUGE = "gauge"


class EmbeddingLineChartParametersInterpolate(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """How to fill missing data points."""

    NONE = "none"
    ZERO = "zero"
    PREVIOUS = "previous"
    INTERPOLATE = "interpolate"


class EmbeddingLineChartParametersLineStyle(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """Line style to use in the chart."""

    SMOOTH = "smooth"
    LINE = "line"
    STEP = "step"


class EmbeddingLineChartParametersModuleName(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """EmbeddingLineChartParametersModuleName."""

    LINE_CHART = "line_chart"


class EmbeddingLineChartParametersPoints(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Show or hide the point markers."""

    HIDE = "hide"
    SHOW = "show"


class EmbeddingLineChartParametersXAxisCustomizationLabelOrientation(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """Orientation of the x-axis labels."""

    HORIZONTAL = "horizontal"
    AUTO = "auto"
    ANGLED = "angled"


class EmbeddingLinkRequestPayloadLayout(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Show or hide the controls surrounding the visualization."""

    ENTIRE_VIEW = "entire-view"
    VISUALIZATION_ONLY = "visualization-only"


class EmbeddingMeasureFilterMaxOp(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """EmbeddingMeasureFilterMaxOp."""

    GTE = "gte"
    GT = "gt"


class EmbeddingMeasureFilterMinOp(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """EmbeddingMeasureFilterMinOp."""

    LTE = "lte"
    LT = "lt"


class EmbeddingMeasureFilterType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """EmbeddingMeasureFilterType."""

    MEASURE = "measure"


class EmbeddingNumericFilterIntervalEndBound(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """EmbeddingNumericFilterIntervalEndBound."""

    LTE = "lte"
    LT = "lt"


class EmbeddingNumericFilterIntervalStartBound(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """EmbeddingNumericFilterIntervalStartBound."""

    GT = "gt"
    GTE = "gte"


class EmbeddingNumericFilterType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """EmbeddingNumericFilterType."""

    NUMERIC = "numeric"


class EmbeddingOverallParametersConditionalFormattingItemIntent(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """Caution level."""

    WARNING = "WARNING"
    DANGER = "DANGER"
    OK = "OK"


class EmbeddingOverallParametersConditionalFormattingItemType(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """Condition."""

    SMALLER_THAN = "smallerThan"
    LARGER_THAN = "largerThan"
    SMALLER_THAN_OR_EQUAL_TO = "smallerThanOrEqualTo"
    LARGER_THAN_OR_EQUAL_TO = "largerThanOrEqualTo"
    BETWEEN = "between"
    OUTSIDE_OF = "outsideOf"


class EmbeddingOverallParametersModuleName(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """EmbeddingOverallParametersModuleName."""

    OVERALL = "overall"


class EmbeddingStringFilterOperator(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """EmbeddingStringFilterOperator."""

    EQ = "eq"
    NE = "ne"
    CONTAINS = "contains"
    IN = "in"


class EmbeddingStringFilterType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """EmbeddingStringFilterType."""

    STRING = "string"


class EmbeddingTimeFilterIntervalTimeType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """EmbeddingTimeFilterIntervalTimeType."""

    FIXED = "fixed"
    LATEST = "latest"
    PREVIOUS = "previous"
    CURRENT = "current"


class EmbeddingTimeFilterType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """EmbeddingTimeFilterType."""

    TIME = "time"


class EmbeddingTimeSeriesParametersAggregationMethod(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """Specifies the method Polaris uses to aggregate data over time:


    * ``TIME_WEIGHTED_AVERAGE``\\ : Calculates the average value of data points, weighted by the
    time between them.
    * ``DOWNSAMPLED_SUM_TIME_SERIES``\\ : Sums data points within specified intervals, reducing the
    resolution of the data.
    """

    TIME_WEIGHTED_AVERAGE = "TIME_WEIGHTED_AVERAGE"
    DOWNSAMPLED_SUM_TIME_SERIES = "DOWNSAMPLED_SUM_TIME_SERIES"


class EmbeddingTimeSeriesParametersInterpolator(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """How to fill missing data points."""

    LINEAR = "linear"
    PADDING = "padding"
    BACKFILL = "backfill"


class EmbeddingTimeSeriesParametersModuleName(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """EmbeddingTimeSeriesParametersModuleName."""

    TIME_SERIES = "time_series"


class EmbeddingTimeSeriesParametersRenderType(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """Type of chart."""

    LINE = "line"
    BAR = "bar"


class EmbeddingTimeSeriesParametersTimeseriesBucket(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """Bucketing period for the time dimension to use."""

    PT1_M = "PT1M"
    PT5_M = "PT5M"
    PT1_H = "PT1H"
    P1_D = "P1D"


class EmbeddingTimeSeriesParametersTimeseriesFunction(
    str, Enum, metaclass=CaseInsensitiveEnumMeta
):
    """Function to transform or augment a time series."""

    TIMESERIES = "TIMESERIES"
    DELTA_TIMESERIES = "DELTA_TIMESERIES"
    ADD_TIMESERIES = "ADD_TIMESERIES"
    DIVIDE_TIMESERIES = "DIVIDE_TIMESERIES"
    MULTIPLY_TIMESERIES = "MULTIPLY_TIMESERIES"
    SUBTRACT_TIMESERIES = "SUBTRACT_TIMESERIES"


class EmbeddingTransform(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Transform type to apply."""

    NONE = "none"
    PERCENT_OF_PARENT = "percent-of-parent"
    PERCENT_OF_ROOT = "percent-of-root"


class EmbedLinkDescriptionLayout(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Show or hide the controls surrounding the visualization."""

    ENTIRE_VIEW = "entire-view"
    VISUALIZATION_ONLY = "visualization-only"


class Enum183(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Enum183."""

    INHERIT = "inherit"


class Enum184(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Enum184."""

    PREVIOUS_PERIOD = "previous-period"


class ExploreColorRangeMaxOp(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Operator for the upper bound of a color range."""

    LESS_THAN = "lessThan"
    LESS_THAN_OR_EQUAL = "lessThanOrEqual"


class ExploreColorRangeMinOp(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Operator for the lower bound of a color range."""

    GREATER_THAN = "greaterThan"
    GREATER_THAN_OR_EQUAL = "greaterThanOrEqual"


class ExploreEssenceModuleName(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visual module to use."""

    OVERALL = "overall"
    GAUGE = "gauge"
    FLAT_TABLE = "flat_table"
    TIME_SERIES = "time_series"
    LINE_CHART = "line_chart"
    RECORDS_TABLE = "records_table"
    BAR_CHART = "bar_chart"


class ExploreSplitCombineSortDirection(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Sort direction to use."""

    ASC = "ASC"
    DESC = "DESC"


class FacetCompareType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Comparison type."""

    TIME_RELATIVE = "time-relative"
    TIME_ABSOLUTE = "time-absolute"
    UNFILTER = "unfilter"
    FILTER = "filter"
    MEASURE = "measure"


class FacetVisualizationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """FacetVisualizationType."""

    TABLE = "table"
    LINE_CHART = "line-chart"
    VERTICAL_BARS = "vertical-bars"
    HORIZONTAL_BARS = "horizontal-bars"
    HEATMAP = "heatmap"
    SPOT_MATRIX = "spot-matrix"
    TREEMAP = "treemap"
    PIE_CHART = "pie-chart"
    SUNBURST = "sunburst"
    GEO_MARKS = "geo-marks"
    SPARKLINE = "sparkline"
    STACK_AREA_CHART = "stack-area-chart"
    TOTALS = "totals"
    RECORDS = "records"
    PATH_TREE = "path-tree"
    GEO_SHADE = "geo-shade"
    BUBBLE_CHART = "bubble-chart"
    SANKEY = "sankey"
    STREET_MAP = "street-map"
    RECORDS_TABLE = "records-table"


class FieldNameAndDataTypeDataType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Data type of the input field."""

    BIGINT = "bigint"
    COMPLEX_JSON_ = "complex<json>"
    DOUBLE = "double"
    FLOAT = "float"
    GEO = "geo"
    HLL_SKETCH = "HLLSketch"
    IP_ADDRESS = "ipAddress"
    IP_PREFIX = "ipPrefix"
    JSON = "json"
    LONG = "long"
    LONG_STRING_PAIR = "longStringPair"
    DOUBLE_ARRAY = "doubleArray"
    FLOAT_ARRAY = "floatArray"
    LONG_ARRAY = "longArray"
    STRING_ARRAY = "stringArray"
    QUANTILES_DOUBLES_SKETCH = "quantilesDoublesSketch"
    STRING = "string"
    THETA_SKETCH = "thetaSketch"
    INGEST_TIMESERIES = "ingest_timeseries"
    TIMESTAMP = "timestamp"
    VARCHAR = "varchar"
    VARIANCE = "variance"


class FileSortColumn(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """An enum indicating a file column to sort by and/or search values for.


    * ``compression_format``    - The compression used for the file.
    * ``data_format``           - The data format used for the file.
    * ``name``                  - The file name.
    * ``size_bytes``            - The size of the file in bytes.
    * ``uploaded_by_user_name`` - The name of the user that uploaded the file.
    * ``uploaded_on_dt``        - The date the file was uploaded on.
    """

    COMPRESSION_FORMAT = "compression_format"
    DATA_FORMAT = "data_format"
    DIGEST_ALGO = "digest_algo"
    DIGEST_HASH = "digest_hash"
    NAME = "name"
    SIZE_BYTES = "size_bytes"
    UPLOADED_BY_USER_NAME = "uploaded_by_user_name"
    UPLOADED_ON_DT = "uploaded_on_dt"


class FilterAction(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Action performed by a filter clause."""

    OVERLAP = "overlap"
    CONTAINS = "contains"
    MATCH = "match"
    INTERSECT = "intersect"
    IP_MATCH = "ipMatch"


class GeoEncodingType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The geo encoding type for a dimension. Geo dimensions require specific data types to be set
    depending on the geo encoding type. For ``lat-coordinate`` or ``lng-coordinate`` dimensions,
        set the type to ``number``. For all other geo encodings, set the type to ``string``.
    """

    ISO3166_1_ALPHA2 = "ISO 3166-1 Alpha-2"
    ISO3166_1_ALPHA3 = "ISO 3166-1 Alpha-3"
    ISO3166_2 = "ISO 3166-2"
    UN_M49 = "UN M49"
    GEOHASH = "Geohash"
    LNG_COORDINATE = "lng-coordinate"
    LAT_COORDINATE = "lat-coordinate"


class GeoMarksType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    GEO_MARKS = "geo-marks"


class GeoShadeType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    GEO_SHADE = "geo-shade"


class GranularityType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The type of granularity.


    * ``simple``\\ - Simple granularity such as ``millisecond`` or ``hour``.
    * ``period``\\ - Period-based granularity that accepts an ISO 8601 period such as ``P6M``.
    Allows specification of time zone and origin.
    """

    SIMPLE = "simple"
    PERIOD = "period"


class HavingFilterOperator(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Operator for a HAVING filter."""

    LESS_THAN = "lessThan"
    GREATER_THAN = "greaterThan"


class HeatMapType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    HEATMAP = "heatmap"


class HorizontalBarsType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    HORIZONTAL_BARS = "horizontal-bars"


class IngestionModeV2(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Mode of ingestion:


    * ``append``  - Append newly ingested data to the existing data. To ingest a certain time range
    of source data,
      apply a `filter expression <https://docs.imply.io/ui/saas/help/ingest-with-filters.html>`_ to
    filter by a given time interval.
    * ``replace`` - Overwrite existing data for specific time intervals or all data in the table.
      Specify specific time intervals in ``target.intervals``\\ , or set ``"replaceAll": true``.
      To restrict the time interval of what data Polaris ingests, use
      `filter expressions <https://docs.imply.io/ui/saas/help/ingest-with-filters.html>`_.
    """

    APPEND = "append"
    REPLACE = "replace"


class JobErrorCodeV2(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Status returned when a job completed with error. The following error statuses may be returned:


    * ``canceled``                            - The job was canceled.
    * ``cannot_parse_multi_value_dimension``  - The input contains multi-value dimension(s). Please
    wrap them in MV_TO_ARRAY().
    * ``cannot_parse_source``                 - The input source could not be parsed with the given
    format/configuration.
    * ``column_name_restricted``              - A column used a restricted column name.
    * ``column_type_not_supported``           - A column has an unsupported type.
    * ``could_not_connect_to_source``         - Polaris could not connect to the source input.
    * ``internal_error``                      - An internal error occurred. Please retry your
    request and contact support if the issue persists.
    * ``invalid_null_byte``                   - The input data contained a string with a null byte.
    * ``multiple``                            - Multiple errors resulted. See the `job logs
    <#tag/projectJobs/operation/describeJobLogsInProject>`_ for details.
    * ``no_rows_ingested``                    - An ingestion job produced no rows. Please check
    your data, timestamp mapping, and any ingestion filters.
    * ``null_timestamp``                      - The input data contained a null timestamp.
    * ``query_not_supported``                 - The ingestion query is not supported.
    * ``row_too_large``                       - The input data contained a row that was too large.
    * ``timestamp_out_of_bounds``             - The input data contained a timestamp outside of the
    bounds specified by OVERWRITE WHERE.
    * ``too_many_clustered_by_columns``       - The job is clustering by too many columns.
    * ``too_many_columns``                    - The job is creating too many output columns.
    * ``too_many_input_files``                - The job is ingesting too many input files.
    * ``too_many_partitions``                 - The job is creating too many output partitions.
    * ``too_many_rows_with_same_key``         - The input data contains too many rows with the same
    key.
    * ``too_many_time_buckets``               - The job is creating too many time buckets in the
    output.
    """

    CANCELED = "canceled"
    CANNOT_PARSE_MULTI_VALUE_DIMENSION = "cannot_parse_multi_value_dimension"
    CANNOT_PARSE_SOURCE = "cannot_parse_source"
    COLUMN_NAME_RESTRICTED = "column_name_restricted"
    COLUMN_TYPE_NOT_SUPPORTED = "column_type_not_supported"
    COULD_NOT_CONNECT_TO_SOURCE = "could_not_connect_to_source"
    INTERNAL_ERROR = "internal_error"
    INVALID_NULL_BYTE = "invalid_null_byte"
    MULTIPLE = "multiple"
    NO_ROWS_INGESTED = "no_rows_ingested"
    NULL_TIMESTAMP = "null_timestamp"
    QUERY_NOT_SUPPORTED = "query_not_supported"
    ROW_TOO_LARGE = "row_too_large"
    TIMESTAMP_OUT_OF_BOUNDS = "timestamp_out_of_bounds"
    TOO_MANY_CLUSTERED_BY_COLUMNS = "too_many_clustered_by_columns"
    TOO_MANY_COLUMNS = "too_many_columns"
    TOO_MANY_INPUT_FILES = "too_many_input_files"
    TOO_MANY_PARTITIONS = "too_many_partitions"
    TOO_MANY_ROWS_WITH_SAME_KEY = "too_many_rows_with_same_key"
    TOO_MANY_SEGMENTS_IN_TIME_CHUNK = "too_many_segments_in_time_chunk"
    TOO_MANY_TIME_BUCKETS = "too_many_time_buckets"


class JobExecutionStatusV2(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The execution status of the job.


    * ``pending``   - The job is waiting to run. Jobs are typically in this state when they are
    awaiting resources.
    * ``running``   - The job is currently in progress.
    * ``completed`` - The job completed. Refer to the job's ``health`` field to check for any
    warnings or errors.
    * ``idle``      - The job is idle. This may occur when a streaming ingestion job has no data to
    ingest.
    * ``canceled``  - The job was canceled by the user.
    * ``failed``    - The job failed. Refer to the job's ``health`` field for more details about
    the failure.
    * ``suspended`` - The job is suspended by the user.
    * ``unknown``   - The execution status of the job is not known. This state typically occurs
    when a downstream error prevents retrieval of the job execution status. If a job persists in
    this state for an extended period of time (more than a few minutes), please contact Imply.
    """

    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    IDLE = "idle"
    CANCELED = "canceled"
    FAILED = "failed"
    SUSPENDED = "suspended"
    UNKNOWN = "unknown"


class JobHealthStatusV2(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The health status of the job.


    * ``ok``        - The job is in good health with no warnings or errors raised.
    * ``warn``      - The job has one or more warnings.
    * ``error``     - The job has one or more errors.
    """

    OK = "ok"
    WARN = "warn"
    ERROR = "error"


class JobResponseExecutionStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """JobResponseExecutionStatus."""

    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    IDLE = "idle"
    CANCELED = "canceled"
    FAILED = "failed"
    SUSPENDED = "suspended"
    UNKNOWN = "unknown"


class JobSortSearchColumn(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """This description doesn't show up in docs. Make any changes
    to where JobSortSearchColumn is referenced (ex. sortColumn).

    An enum indicating a job column to sort by and/or search values for.


    * ``created_by_user_name``     : User that created the job.
    * ``created_date_time``        : Date the job was created.
    * ``execution_status``         : Job's execution status.
    * ``last_updated_date_time``   : Date the job was last updated.
    * ``source_name``              : Job's source name, such as a connection name.
    * ``source_type``              : Job's source type, such as ``connection`` or ``table``.
    * ``source_connection_name``   : Deprecated, use ``source_name`` instead.
    * ``source_table_name``        : Deprecated, use ``source_name`` instead.
    * ``target_table_name``        : Table that the job targets.
    * ``type``                     : Job type.
    """

    CREATED_BY_USER_NAME = "created_by_user_name"
    CREATED_DATE_TIME = "created_date_time"
    EXECUTION_STATUS = "execution_status"
    LAST_UPDATED_DATE_TIME = "last_updated_date_time"
    SOURCE_NAME = "source_name"
    SOURCE_TYPE = "source_type"
    SOURCE_CONNECTION_NAME = "source_connection_name"
    SOURCE_TABLE_NAME = "source_table_name"
    TARGET_TABLE_NAME = "target_table_name"
    TYPE = "type"


class JobSourceTypeV2(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Source of input data for an ingestion job:
    
    
    * ``azure``\\ : Ingest data from an Azure Blob Storage connection.
    * ``connection``\\ : Ingest data from a connection. Don't use this source type for ``azure``\\
    , ``s3``\\ , or ``sql`` connections.
    * ``s3``\\ : Ingest data from an Amazon S3 connection.
    * ``table``\\ : Ingest data from an existing Polaris table.
    * ``inline``\\ : Ingest inline data.
    * ``uploaded``\\ : Ingest data from one or more files uploaded to Polaris.
    """

    AZURE = "azure"
    CONNECTION = "connection"
    S3 = "s3"
    TABLE = "table"
    INLINE = "inline"
    UPLOADED = "uploaded"


class JobTargetTypeV2(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of job target.


    * ``table`` - Specifies that the job target is a table.
    """

    TABLE = "table"


class JobTypeV2(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of job:


    * ``batch``        - A batch ingestion job.
    * ``delete_data``  - A job to delete data within a table.
    * ``drop_table``   - A job to delete a table and all of its data.
    * ``restore_data`` - A job to restore deleted data in a table.
    * ``streaming``    - A streaming ingestion job.
    *
      ``sql``          - A SQL-based ingestion job.

      You can't drop a table that's used as a lookup source.

      For information about ingestion jobs, see
      `Create an ingestion job <https://docs.imply.io/ui/saas/help/ingestion-job.html>`_ and
      `Ingest using SQL <https://docs.imply.io/ui/saas/help/sql-based-ingestion.html>`_.
    """

    BATCH = "batch"
    DELETE_DATA = "delete_data"
    DROP_TABLE = "drop_table"
    RESTORE_DATA = "restore_data"
    STREAMING = "streaming"
    SQL = "sql"


class JobWarningCodeV2(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The warning code of the job. Warnings are non-fatal, so the job may still be running if a
    warning has been
    encountered. The following warning codes may be returned:


    * ``lost_connection_to_source`` - Polaris lost its connection to the source input that it had
    previously connected to.
    * ``no_rows_found``             - The job completed without ingesting or deleting any rows of
    data.
    * ``invalid_rows_found``        - Polaris detected invalid rows in the input data.
    * ``unable_to_proceed``         - Polaris was unable to proceed with ingestion.
    * ``multiple``                  - The job completed with multiple warnings. See the `job logs
    <#tag/projectJobs/operation/describeJobLogsInProject>`_ for details.
    """

    LOST_CONNECTION_TO_SOURCE = "lost_connection_to_source"
    NO_ROWS_FOUND = "no_rows_found"
    INVALID_ROWS_FOUND = "invalid_rows_found"
    UNABLE_TO_PROCEED = "unable_to_proceed"
    MULTIPLE = "multiple"


class KafkaConnectionSslKeystoreType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """SSL keystore type."""

    PEM = "pem"


class KafkaConnectionSslTruststoreType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """SSL truststore type."""

    PEM = "pem"


class LatestDataStrategy(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Determines how Polaris calculates the latest data time for the data cube.
    By default, Polaris queries the data source for the latest time stamp on ingested data.
    You can set this property to always use the current time, which may be more appropriate for
    streaming data.
    """

    QUERY = "query"
    QUERY_FLOORED_P1_D = "query-floored-P1D"
    PREDEFINED = "predefined"


class LegendSide(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Side of the tile to display the legend."""

    NONE = "none"
    RIGHT = "right"
    BOTTOM = "bottom"


class LineChartType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Visualization type."""

    LINE_CHART = "line-chart"


class LiveMeasureTransform(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Transformation to apply to a measure."""

    NONE = "none"
    PERCENT_OF_PARENT = "percent-of-parent"
    PERCENT_OF_ROOT = "percent-of-root"
    PERCENT_OF_FIRST_AXIS = "percent-of-first-axis"
    PERCENT_OF_SECOND_AXIS = "percent-of-second-axis"


class LogoFileType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """File type."""

    PNG = "png"
    SVG = "svg"


class LogoKind(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Logo type."""

    FULL = "full"
    FAVICON = "favicon"


class LookupSourcePayloadType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """LookupSourcePayloadType."""

    TABLE = "table"


class MeasureFilter1FilterType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """MeasureFilter1FilterType."""

    MEASURE = "measure"


class MeasureFilter1MaxOp(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """MeasureFilter1MaxOp."""

    GTE = "gte"
    GT = "gt"


class MeasureFilter1MinOp(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """MeasureFilter1MinOp."""

    LTE = "lte"
    LT = "lt"


class MeasureFilterFromOperator(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Operator for the lower bound on a measure filter."""

    GREATER_THAN = "greaterThan"
    GREATER_THAN_OR_EQUAL = "greaterThanOrEqual"


class MeasureFilterToOperator(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Operator for the upper bound on a measure filter."""

    LESS_THAN = "lessThan"
    LESS_THAN_OR_EQUAL = "lessThanOrEqual"


class MeasureTransform(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """You can transform a measure to be displayed as Percent of parent segment or as Percent of total
    instead
    of the default measure display.
    """

    NONE = "none"
    PERCENT_OF_PARENT = "percent-of-parent"
    PERCENT_OF_ROOT = "percent-of-root"


class MissingValueFill(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Specifies how to fill empty values for a measure on continuous visualizations:


    * ``zero``\\ : (default) Fill missing data with zeros. This is most suitable if the measure
    represents an additive quantity.
    * ``none``\\ : Leave missing data empty. This is suitable when missing values indicate that the
    data is not collected.
    * ``previous``\\ : Fill missing data with last value seen. This is suitable for sensor type
    data.
    * ``interpolate``\\ : Interpolate the missing data between the seen value. This is suitable for
    sensor type data.
    """

    ZERO = "zero"
    NONE = "none"
    PREVIOUS = "previous"
    INTERPOLATE = "interpolate"


class MultiMeasureMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Controls how measures display when multiple measures are selected."""

    ROW = "row"
    COLUMN = "column"
    CELL = "cell"


class NetworkPolicyDetailsPolicy(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Allow access from the specified IP address or CIDR."""

    ALLOW = "allow"


class NumericFilterOperator(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """NumericFilterOperator."""

    GT = "gt"
    GTE = "gte"
    LT = "lt"
    LTE = "lte"
    EQ = "eq"
    NE = "ne"


class NumericFilterType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """NumericFilterType."""

    NUMERIC = "numeric"


class ParseSchemaProviderType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Data format:


    * ``connection`` - Retrieves the parse schema from an external source defined by a connection.
    * ``inline-avro`` - An inline Avro schema.
    * ``inline-protobuf`` - An inline compiled Protobuf descriptor, encoded as a Base64 string.
    """

    CONNECTION = "connection"
    INLINE_AVRO = "inline-avro"
    INLINE_PROTOBUF = "inline-protobuf"


class PartitioningGranularity(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Optional `time partitioning <https://docs.imply.io/ui/saas/help/partitioning.html>`_. If
    specified,
    takes precedence over the time partitioning defined on the target table.
    If unspecified, defaults to the time partitioning of the table.

    When ingesting into a lookup table, you can only set ``all`` partitioning.
    """

    SECOND = "second"
    MINUTE = "minute"
    FIVE_MINUTE = "five_minute"
    TEN_MINUTE = "ten_minute"
    FIFTEEN_MINUTE = "fifteen_minute"
    THIRTY_MINUTE = "thirty_minute"
    HOUR = "hour"
    SIX_HOUR = "six_hour"
    EIGHT_HOUR = "eight_hour"
    DAY = "day"
    MONTH = "month"
    QUARTER = "quarter"
    YEAR = "year"
    ALL = "all"


class PathTreeType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    PATH_TREE = "path-tree"


class PieChartType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    PIE_CHART = "pie-chart"


class PlywoodType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The concrete type for a single datum."""

    NULL = "NULL"
    BOOLEAN = "BOOLEAN"
    NUMBER = "NUMBER"
    TIME = "TIME"
    STRING = "STRING"
    NUMBER_RANGE = "NUMBER_RANGE"
    IP = "IP"
    TIME_SERIES = "TIME_SERIES"
    TIME_RANGE = "TIME_RANGE"
    STRING_RANGE = "STRING_RANGE"
    SET = "SET"
    SET_NULL = "SET/NULL"
    SET_BOOLEAN = "SET/BOOLEAN"
    SET_NUMBER = "SET/NUMBER"
    SET_TIME = "SET/TIME"
    SET_STRING = "SET/STRING"
    SET_NUMBER_RANGE = "SET/NUMBER_RANGE"
    SET_TIME_RANGE = "SET/TIME_RANGE"
    SET_IP = "SET/IP"
    SET_STRING_RANGE = "SET/STRING_RANGE"
    DATASET = "DATASET"


class ProjectSpecDesiredState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Desired state of the project."""

    RUNNING = "running"
    PAUSED = "paused"
    STOPPED = "stopped"


class ProjectStatusState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Current state of the project.


    * ``creating`` - The project is in creation.
    * ``pending`` - The project is pending for creation or update.
    * ``running`` - The project is running.
    * ``pausing`` - The project is being paused.
    * ``paused`` -  The project is paused while the storage volume is kept.
    * ``stopping`` - The project is being stopped.
    * ``stopped`` - The project is stopped while the storage volume is also removed.
    * ``deleting`` - The project is being deleted.
    * ``deleted`` - The project is deleted.
    * ``updating`` - The project is being updated.
    * ``balancing`` - The segments are being balanced when the project is scaling up and down.
    * ``failed`` - The project is failed.
    * ``resuming`` - The project is being resumed from ``paused`` or ``stopped`` state.
    * ``unknown`` - The project is in unknown state.
    * ``restarting`` - The project is restarting.
    """

    CREATING = "creating"
    PENDING = "pending"
    RUNNING = "running"
    PAUSING = "pausing"
    PAUSED = "paused"
    STOPPING = "stopping"
    STOPPED = "stopped"
    DELETING = "deleting"
    DELETED = "deleted"
    UPDATING = "updating"
    BALANCING = "balancing"
    FAILED = "failed"
    RESUMING = "resuming"
    UNKNOWN = "unknown"
    RESTARTING = "restarting"


class QueryMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Data cube query mode."""

    SQL = "sql"
    PLYWOOD = "plywood"


class RawType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    RAW = "raw"


class RegionEnum(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Cloud region for the project. For supported regions, see `Cloud providers and regions
    <https://docs.imply.io/polaris/regions>`_.
    """

    US_EAST1 = "us-east-1"
    US_EAST2 = "us-east-2"
    EU_CENTRAL1 = "eu-central-1"
    EU_WEST1 = "eu-west-1"
    US_WEST2 = "us-west-2"
    AP_NORTHEAST2 = "ap-northeast-2"
    AP_SOUTH1 = "ap-south-1"
    EASTUS = "eastus"
    GERMANYWESTCENTRAL = "germanywestcentral"
    WESTUS2 = "westus2"


class RelativeCompareType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """RelativeCompareType."""

    RELATIVE = "relative"


class ReportEvaluationErrorType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of error that occurred during report evaluation."""

    INTERNAL_ERROR = "internal-error"
    MISCONFIGURATION_ERROR = "misconfiguration-error"
    EMAIL_ERROR = "email-error"


class ReportPayloadFileFormat(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Format of the report data attachment. Defaults to ``CSV``."""

    CSV = "csv"
    TSV = "tsv"
    XLSX = "xlsx"
    JSON = "json"


class ReportPayloadPreferredView(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """View to use when viewing the report in Polaris. Defaults to ``pivot1``. When supplying
    a ``facetEssence``\\ , set to ``pivot2``. When supplying an ``exploreEssence``\\ , set to
    ``explore``.
    """

    PIVOT1 = "pivot1"
    PIVOT2 = "pivot2"
    EXPLORE = "explore"


class ResultFormat(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """String that indicates the format to return query results. Select one of the following formats:


    * `object`: Returns a JSON array of JSON objects with the HTTP response header `Content-Type:
    application/json`.
       Object field names match the columns returned by the SQL query in the same order as the SQL
    query.


    *
      `array`: Returns a JSON array of JSON arrays with the HTTP response header `Content-Type:
    application/json`.
       Each inner array has elements matching the columns returned by the SQL query, in order.

    *
      `objectLines`: Returns newline-delimited JSON objects with the HTTP response header
    `Content-Type: text/plain`.
       Newline separation facilitates parsing the entire response set as a stream if you don't have
    a streaming JSON parser.
       This format includes a single trailing newline character so you can detect a truncated
    response.

    *
      `arrayLines`: Returns newline-delimited JSON arrays with the HTTP response header
    `Content-Type: text/plain`.
       Newline separation facilitates parsing the entire response set as a stream if you don't have
    a streaming JSON parser.
       This format includes a single trailing newline character so you can detect a truncated
    response.

    *
      `csv`: Returns comma-separated values with one row per line. Sent with the HTTP response
    header `Content-Type: text/csv`.

       Druid uses double quotes to escape individual field values. For example, a value with a
    comma returns ``"A,B"``.
       If the field value contains a double quote character, Druid escapes it with a second double
    quote character.
       For example, ``foo"bar`` becomes ``foo""bar``.
       This format includes a single trailing newline character so you can detect a truncated
    response.
    """

    OBJECT = "object"
    ARRAY = "array"
    OBJECT_LINES = "objectLines"
    ARRAY_LINES = "arrayLines"
    CSV = "csv"


class SankeyType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    SANKEY = "sankey"


class SaslScramMechanismPayload(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The SASL/SCRAM mechanism to use:


    * ``SCRAM-SHA-256`` to use the SHA-256 algorithm.
    * ``SCRAM-SHA-512`` to use the SHA-512 algorithm.

    The specified mechanism must be included in ``sasl.enabled.mechanisms`` in the Kafka cluster's
    configuration.
    """

    SCRAM_SHA256 = "SCRAM-SHA-256"
    SCRAM_SHA512 = "SCRAM-SHA-512"


class ScaleBehavior(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Determines how the scale behaves in "continuous" visualizations (such as the line chart):


    * ``pin-zero``\\ : Always include 0 for reference.
    * ``unpinned``\\ : Do not force 0 into the scale.
    """

    PIN_ZERO = "pin-zero"
    UNPINNED = "unpinned"


class Severity(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Severity determines the alert's color and icon in the Polaris UI."""

    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    OK = "ok"


class ShowHide(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """ShowHide."""

    SHOW = "show"
    HIDE = "hide"


class SingleAccessListAccess(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """SingleAccessListAccess."""

    SINGLE = "single"


class SortOrder(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """SortOrder."""

    ASC = "ASC"
    DESC = "DESC"


class SparkLineType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    SPARK_LINE = "spark-line"


class SpecificAccessListAccess(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """SpecificAccessListAccess."""

    SPECIFIC = "specific"


class SplitCombineSortDirection(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Sort direction for a split combine."""

    ASCENDING = "ascending"
    DESCENDING = "descending"


class SplitCombineSortType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Sort type for a split combine."""

    DIMENSION = "dimension"
    MEASURE = "measure"
    MEASURE_DELTA = "measure-delta"
    MEASURE_PERCENT_DELTA = "measure-percent-delta"
    MEASURE_ABSOLUTE_DELTA = "measure-absolute-delta"
    MEASURE_ABSOLUTE_PERCENT_DELTA = "measure-absolute-percent-delta"


class SpotMatrixType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    SPOT_MATRIX = "spot-matrix"


class SqlErrorResponseCategory(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Classification of the error."""

    DEFENSIVE = "DEFENSIVE"
    INVALID_INPUT = "INVALID_INPUT"
    UNAUTHORIZED = "UNAUTHORIZED"
    FORBIDDEN = "FORBIDDEN"
    CAPACITY_EXCEEDED = "CAPACITY_EXCEEDED"
    CANCELED = "CANCELED"
    RUNTIME_FAILURE = "RUNTIME_FAILURE"
    TIMEOUT = "TIMEOUT"
    UNSUPPORTED = "UNSUPPORTED"
    UNCATEGORIZED = "UNCATEGORIZED"


class SqlState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """State of the query."""

    ACCEPTED = "ACCEPTED"
    RUNNING = "RUNNING"
    FAILED = "FAILED"
    SUCCESS = "SUCCESS"


class StackAreaChartType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    STACK_AREA_CHART = "stack-area-chart"


class StoragePolicyType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The type of storage policy to set."""

    INTERVALS = "intervals"
    PERIOD = "period"


class StreamingReadFromPoint(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Sets the point to start reading from in a stream:


    * ``earliest`` tells Polaris to read data from the earliest available point in the stream. Use
    this if there is already data in the stream that you wish to ingest. Note that Polaris will
    only ingest data whose timestamp is within the last 30 days. If you have older data you wish to
    ingest, we recommend exporting it to a file and batch ingesting it.
    * ``latest`` tells Polaris to read data from the latest point available in the stream. Polaris
    will only ingest data published to the stream after the job is created (provided the data's
    timestamp is within the last 30 days).
    """

    EARLIEST = "earliest"
    LATEST = "latest"


class StringFilterOperator(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """StringFilterOperator."""

    EQ = "eq"
    NE = "ne"
    CONTAINS = "contains"
    IN = "in"


class StringFilterType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """StringFilterType."""

    STRING = "string"


class SunburstType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    SUNBURST = "sunburst"


class TableAvailability(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The availability status of the table:


    * ``available``   - All data in table is available for querying.
    * ``deleting``    - The table is being deleted.
    * ``unavailable`` - Not all data in the table is available for querying.
    """

    AVAILABLE = "available"
    DELETING = "deleting"
    UNAVAILABLE = "unavailable"


class TableColumnDataType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The expected data type of the column. Reserve the ``timestamp`` data type for the primary
    timestamp column ``__time``.
    """

    BIGINT = "bigint"
    COMPLEX_JSON_ = "complex<json>"
    DOUBLE = "double"
    FLOAT = "float"
    GEO = "geo"
    HLL_SKETCH = "HLLSketch"
    IP_ADDRESS = "ipAddress"
    IP_PREFIX = "ipPrefix"
    JSON = "json"
    LONG = "long"
    LONG_STRING_PAIR = "longStringPair"
    DOUBLE_ARRAY = "doubleArray"
    FLOAT_ARRAY = "floatArray"
    LONG_ARRAY = "longArray"
    STRING_ARRAY = "stringArray"
    QUANTILES_DOUBLES_SKETCH = "quantilesDoublesSketch"
    STRING = "string"
    THETA_SKETCH = "thetaSketch"
    INGEST_TIMESERIES = "ingest_timeseries"
    TIMESTAMP = "timestamp"
    VARCHAR = "varchar"
    VARIANCE = "variance"


class TablePartitioningGranularity(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The `time partitioning <https://docs.imply.io/ui/saas/help/partitioning.html>`_ of the table.
    The ``all`` granularity groups all data into a single bucket. The ``week`` granularity is
    deprecated. You can't create a new table with the time partitioning set to ``week``. A table
    sourced by a lookup can only use all partitioning. You can’t change this setting on a table
    that’s actively used by a lookup.
    """

    SECOND = "second"
    MINUTE = "minute"
    FIVE_MINUTE = "five_minute"
    TEN_MINUTE = "ten_minute"
    FIFTEEN_MINUTE = "fifteen_minute"
    THIRTY_MINUTE = "thirty_minute"
    HOUR = "hour"
    SIX_HOUR = "six_hour"
    EIGHT_HOUR = "eight_hour"
    DAY = "day"
    WEEK = "week"
    MONTH = "month"
    QUARTER = "quarter"
    YEAR = "year"
    ALL = "all"


class TableSchemaMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The table's schema enforcement mode. For more information, see `Introduction to tables
    <https://docs.imply.io/ui/saas/help/tables.html>`_.
    """

    FLEXIBLE = "flexible"
    STRICT = "strict"


class TableType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Visualization type."""

    TABLE = "table"
    DETAIL = "detail"
    AGGREGATE = "aggregate"


class TileType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Tile type. ``blank`` tiles are empty. ``visualization`` tiles display a data cube
    visualization.
    ``markdown`` tiles display a block of text using `Markdown <https://commonmark.org/help/>`_
    formatting.
    """

    BLANK = "blank"
    VISUALIZATION = "visualization"
    MARKDOWN = "markdown"


class TimeFilterOperator(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """TimeFilterOperator."""

    GT = "gt"
    GTE = "gte"
    LT = "lt"
    LTE = "lte"


class TimeFilterType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """TimeFilterType."""

    _TIME = "__time"


class TimeFrameInterval(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """TimeFrameInterval."""

    PREVIOUS_DAY = "previous_day"
    CURRENT_DAY = "current_day"
    PREVIOUS_WEEK = "previous_week"
    CURRENT_WEEK = "current_week"
    PREVIOUS_MONTH = "previous_month"
    CURRENT_MONTH = "current_month"
    PREVIOUS_QUARTER = "previous_quarter"
    CURRENT_QUARTER = "current_quarter"
    PREVIOUS_YEAR = "previous_year"
    CURRENT_YEAR = "current_year"


class TimeResolution(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The table's rollup granularity. See `Introduction to data rollup
    <https://docs.imply.io/ui/saas/help/rollup.html>`_ for more details.

    You can specify a variable duration or a time zone and origin for a ``period``\\ -type query
    granularity.
    When set, ``queryGranularity`` overrides the rollup granularity in ``timeResolution``.
    """

    MILLISECOND = "millisecond"
    SECOND = "second"
    MINUTE = "minute"
    FIFTEEN_MINUTE = "fifteen_minute"
    THIRTY_MINUTE = "thirty_minute"
    HOUR = "hour"
    DAY = "day"
    WEEK = "week"
    MONTH = "month"
    QUARTER = "quarter"
    YEAR = "year"
    ALL = "all"


class TotalsType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    TOTALS = "totals"


class Transform(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Transform type to apply."""

    NONE = "none"
    PERCENT_OF_PARENT = "percent-of-parent"
    PERCENT_OF_ROOT = "percent-of-root"


class TreeMapType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Name of the visualization."""

    TREEMAP = "treemap"


class UserRepresentationActionsItem(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """UserRepresentationActionsItem."""

    VERIFY_EMAIL = "VERIFY_EMAIL"
    UPDATE_PASSWORD = "UPDATE_PASSWORD"


class VerticalBarsType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Visualization type."""

    VERTICAL_BARS = "vertical-bars"


class Visibility(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Whether a field should be shown or hidden."""

    SHOW = "show"
    HIDE = "hide"


class WebhookType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Specify ``slack`` to send a preconfigured Slack message, or ``custom`` to define a custom
    payload.
    """

    SLACK = "slack"
    CUSTOM = "custom"
