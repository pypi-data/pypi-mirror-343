#!/bin/bash
#SBATCH --partition=PARTITION
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=THREADS_VALUE
#SBATCH --mem=MEMORY
#SBATCH --time=TIME
#SBATCH --job-name=emtax
#SBATCH --output=WORKDIR_PATH/emtax_%j.out
#SBATCH --error=WORKDIR_PATH/emtax_%j.err

# emtax workflow script
# Generated by emtax

echo "Starting emtax workflow at $(date)"

# Set variables
export WORKDIR="WORKDIR_PATH"
export RAWDATA_DIR="RAWDATA_DIR_PATH"
export RESULTS_DIR="RESULTS_DIR_PATH"
export KRAKEN_DB="KRAKEN_DB_PATH"
export CORN_DB="CORN_DB_PATH"
export THREADS=THREADS_VALUE

# Check if conda is available
if command -v conda &> /dev/null; then
    echo "Conda is available"
    
    # Initialize conda for bash
    CONDA_BASE=$(conda info --base)
    source "${CONDA_BASE}/etc/profile.d/conda.sh"
    
    # Activate conda environment
    echo "Activating conda environment: emtax_env"
    conda activate emtax_env
else
    echo "WARNING: Conda not available, proceeding without environment activation"
fi

# Check network connectivity
if ping -c 1 8.8.8.8 &> /dev/null; then
    echo "Network is reachable, using online mode"
else
    echo "WARNING: Network is unreachable, using offline mode"
fi

# Change to workflow directory
cd "${WORKDIR}" || { echo "ERROR: Failed to change to workflow directory"; exit 1; }

echo "Processing samples from config file: ${WORKDIR}/config.yaml"

# Create output directories
mkdir -p "${RESULTS_DIR}/Taxonomic_Profiling/1_DNA_Kraken2"
mkdir -p "${RESULTS_DIR}/Taxonomic_Profiling/2_DNA_Bracken"
mkdir -p "${RESULTS_DIR}/Taxonomic_Profiling/5_DNA_Relative_Abundance_Matrix_Python"

# Create workflow subdirectories
mkdir -p "${WORKDIR}/Preprocessed_Data"
mkdir -p "${WORKDIR}/Logs"

# Process each sample
for SAMPLE in SAMPLES; do
    echo "Processing sample: $SAMPLE"
    
    # Step 1: Check if files are already lane-combined or need combining
    mkdir -p "${WORKDIR}/Preprocessed_Data/combined"
    
    # Check if there are files matching the pattern SampleName_R1/R2.fastq.gz (no lane info)
    NO_LANE_R1=$(find "${RAWDATA_DIR}" -name "${SAMPLE}_R1.fastq.gz" | sort)
    NO_LANE_R2=$(find "${RAWDATA_DIR}" -name "${SAMPLE}_R2.fastq.gz" | sort)
    
    if [ -n "$NO_LANE_R1" ] || [ -n "$NO_LANE_R2" ]; then
        echo "Found files without lane information for ${SAMPLE}, skipping lane combining..."
        # Copy the files directly to the combined directory
        if [ -n "$NO_LANE_R1" ]; then
            cp $NO_LANE_R1 "${WORKDIR}/Preprocessed_Data/combined/${SAMPLE}_R1.fastq.gz"
        fi
        if [ -n "$NO_LANE_R2" ]; then
            cp $NO_LANE_R2 "${WORKDIR}/Preprocessed_Data/combined/${SAMPLE}_R2.fastq.gz"
        fi
    else
        echo "Combining lanes for ${SAMPLE}..."
        # Find all R1 and R2 files for this sample with lane information
        R1_FILES=$(find "${RAWDATA_DIR}" -name "${SAMPLE}_*_R1.fastq.gz" | sort)
        R2_FILES=$(find "${RAWDATA_DIR}" -name "${SAMPLE}_*_R2.fastq.gz" | sort)
        
        # Combine lanes
        cat $R1_FILES > "${WORKDIR}/Preprocessed_Data/combined/${SAMPLE}_R1.fastq.gz"
        cat $R2_FILES > "${WORKDIR}/Preprocessed_Data/combined/${SAMPLE}_R2.fastq.gz"
    fi
    
    # Step 2: Run fastp on combined files
    echo "Running fastp for ${SAMPLE}..."
    if command -v fastp &> /dev/null; then
        mkdir -p "${WORKDIR}/Preprocessed_Data/fastp"
        mkdir -p "${WORKDIR}/Logs/fastp"
        
        fastp -i "${WORKDIR}/Preprocessed_Data/combined/${SAMPLE}_R1.fastq.gz" \
              -I "${WORKDIR}/Preprocessed_Data/combined/${SAMPLE}_R2.fastq.gz" \
              -o "${WORKDIR}/Preprocessed_Data/fastp/${SAMPLE}_R1.fastq.gz" \
              -O "${WORKDIR}/Preprocessed_Data/fastp/${SAMPLE}_R2.fastq.gz" \
              --json "${WORKDIR}/Preprocessed_Data/fastp/${SAMPLE}.json" \
              --html "${WORKDIR}/Preprocessed_Data/fastp/${SAMPLE}.html" \
              --thread "${THREADS}" \
              --report_title "${SAMPLE} Quality Report" \
              > "${WORKDIR}/Logs/fastp/${SAMPLE}.log" 2>&1 || echo "WARNING: fastp failed for ${SAMPLE}"
        
        echo "Fastp reports generated for ${SAMPLE}:"
        ls -la "${WORKDIR}/Preprocessed_Data/fastp/${SAMPLE}.json" "${WORKDIR}/Preprocessed_Data/fastp/${SAMPLE}.html"
    else
        echo "WARNING: fastp not available, skipping quality trimming for ${SAMPLE}"
    fi
    
    # Step 3: Run dehost on fastp output
    echo "Running dehost for ${SAMPLE}..."
    if command -v bowtie2 &> /dev/null; then
        
        # Check if Bowtie2 index exists (either as direct path or in a subdirectory)
        if [ -e "${CORN_DB}.1.bt2" ] || [ -e "${CORN_DB}.1.bt2l" ] || [ -e "${CORN_DB}/corn_db.1.bt2" ] || [ -e "${CORN_DB}/corn_db.1.bt2l" ]; then
            echo "Bowtie2 index found, proceeding with dehosting..."
            
            # Determine the correct index path
            if [ -e "${CORN_DB}.1.bt2" ] || [ -e "${CORN_DB}.1.bt2l" ]; then
                INDEX_PATH="${CORN_DB}"
            else
                INDEX_PATH="${CORN_DB}/corn_db"
            fi
            echo "Using Bowtie2 index at: ${INDEX_PATH}"
            # Run bowtie2 with correct naming
            bowtie2 -p "${THREADS}" -x "${INDEX_PATH}" \
                    -1 "${WORKDIR}/Preprocessed_Data/fastp/${SAMPLE}_R1.fastq.gz" \
                    -2 "${WORKDIR}/Preprocessed_Data/fastp/${SAMPLE}_R2.fastq.gz" \
                    -S /dev/null \
                    --un-conc-gz "${WORKDIR}/Preprocessed_Data/${SAMPLE}_dehost_R%.fastq.gz"
            
            # Check if dehosting was successful
            if [ ! -f "${WORKDIR}/Preprocessed_Data/${SAMPLE}_dehost_R1.fastq.gz" ] || [ ! -f "${WORKDIR}/Preprocessed_Data/${SAMPLE}_dehost_R2.fastq.gz" ]; then
                # Fallback: use fastp output as dehosted files
                cp "${WORKDIR}/Preprocessed_Data/fastp/${SAMPLE}_R1.fastq.gz" "${WORKDIR}/Preprocessed_Data/${SAMPLE}_dehost_R1.fastq.gz"
                cp "${WORKDIR}/Preprocessed_Data/fastp/${SAMPLE}_R2.fastq.gz" "${WORKDIR}/Preprocessed_Data/${SAMPLE}_dehost_R2.fastq.gz"
            fi
            echo "Dehosting completed for ${SAMPLE}"
        else
            echo "WARNING: Bowtie2 index not found at ${CORN_DB}, using fastp output instead"
            # Use fastp output as dehosted files
            ln -sf "${WORKDIR}/Preprocessed_Data/fastp/${SAMPLE}_R1.fastq.gz" "${WORKDIR}/Preprocessed_Data/${SAMPLE}_dehost_R1.fastq.gz"
            ln -sf "${WORKDIR}/Preprocessed_Data/fastp/${SAMPLE}_R2.fastq.gz" "${WORKDIR}/Preprocessed_Data/${SAMPLE}_dehost_R2.fastq.gz"
        fi
    else
        echo "WARNING: bowtie2 not available, using fastp output instead"
        # Use fastp output as dehosted files
        ln -sf "${WORKDIR}/Preprocessed_Data/fastp/${SAMPLE}_R1.fastq.gz" "${WORKDIR}/Preprocessed_Data/${SAMPLE}_dehost_R1.fastq.gz"
        ln -sf "${WORKDIR}/Preprocessed_Data/fastp/${SAMPLE}_R2.fastq.gz" "${WORKDIR}/Preprocessed_Data/${SAMPLE}_dehost_R2.fastq.gz"
    fi
    
    # Step 4: Run kraken2 if available
    if command -v kraken2 &> /dev/null; then
        echo "Running kraken2 for taxonomic classification for ${SAMPLE}..."
        kraken2 --db "${KRAKEN_DB}" \
                --threads "${THREADS}" \
                --paired \
                --output "${RESULTS_DIR}/Taxonomic_Profiling/1_DNA_Kraken2/${SAMPLE}.kraken" \
                --report "${RESULTS_DIR}/Taxonomic_Profiling/1_DNA_Kraken2/${SAMPLE}.report" \
                "${WORKDIR}/Preprocessed_Data/${SAMPLE}_dehost_R1.fastq.gz" \
                "${WORKDIR}/Preprocessed_Data/${SAMPLE}_dehost_R2.fastq.gz" || echo "WARNING: kraken2 failed for ${SAMPLE}"
    else
        echo "WARNING: kraken2 not available, skipping taxonomic classification for ${SAMPLE}"
    fi
    
    # Run bracken if available
    if command -v bracken &> /dev/null && [ -f "${RESULTS_DIR}/Taxonomic_Profiling/1_DNA_Kraken2/${SAMPLE}.report" ]; then
        echo "Running bracken for abundance estimation for ${SAMPLE}..."
        bracken -d "${KRAKEN_DB}" \
                -i "${RESULTS_DIR}/Taxonomic_Profiling/1_DNA_Kraken2/${SAMPLE}.report" \
                -o "${RESULTS_DIR}/Taxonomic_Profiling/2_DNA_Bracken/${SAMPLE}.bracken" \
                -r 150 -l S -t 10 || echo "WARNING: bracken failed for ${SAMPLE}"
    else
        echo "WARNING: bracken not available or kraken2 report missing, skipping abundance estimation for ${SAMPLE}"
    fi
done

# Generate abundance matrix
echo "Generating abundance matrix..."
python "${WORKDIR}/scripts/create_abundance_matrix.py" \
    --input_files "${RESULTS_DIR}"/Taxonomic_Profiling/2_DNA_Bracken/*.bracken \
    --output "${RESULTS_DIR}/Taxonomic_Profiling/5_DNA_Relative_Abundance_Matrix_Python/abundance_matrix.csv" || \
    echo "WARNING: Failed to generate abundance matrix"

echo "emtax workflow finished at $(date)"
