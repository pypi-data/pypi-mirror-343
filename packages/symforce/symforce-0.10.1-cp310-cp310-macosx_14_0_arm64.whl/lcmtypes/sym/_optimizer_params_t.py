# This file automatically generated by skymarshal
# DO NOT MODIFY BY HAND
# fmt: off
# isort: off
# mypy: disallow-untyped-defs
#
# From Source File: /Users/runner/work/symforce/symforce/lcmtypes/symforce.lcm

import copy
import typing as T  # pylint: disable=unused-import

from io import BytesIO
import struct
from lcmtypes.sym._lambda_update_type_t import lambda_update_type_t

class optimizer_params_t(object):
    __slots__: T.List[str] = ["verbose", "debug_stats", "check_derivatives", "include_jacobians", "debug_checks", "initial_lambda", "lambda_lower_bound", "lambda_upper_bound", "lambda_update_type", "lambda_up_factor", "lambda_down_factor", "dynamic_lambda_update_beta", "dynamic_lambda_update_gamma", "dynamic_lambda_update_p", "use_diagonal_damping", "use_unit_damping", "keep_max_diagonal_damping", "diagonal_damping_min", "iterations", "early_exit_min_reduction", "early_exit_min_absolute_error", "enable_bold_updates"]

    def __init__(
        self,
        verbose: bool=False,
        debug_stats: bool=False,
        check_derivatives: bool=False,
        include_jacobians: bool=False,
        debug_checks: bool=False,
        initial_lambda: float=0.0,
        lambda_lower_bound: float=0.0,
        lambda_upper_bound: float=0.0,
        lambda_update_type: T.Optional[lambda_update_type_t]=None,
        lambda_up_factor: float=0.0,
        lambda_down_factor: float=0.0,
        dynamic_lambda_update_beta: float=0.0,
        dynamic_lambda_update_gamma: float=0.0,
        dynamic_lambda_update_p: int=0,
        use_diagonal_damping: bool=False,
        use_unit_damping: bool=False,
        keep_max_diagonal_damping: bool=False,
        diagonal_damping_min: float=0.0,
        iterations: int=0,
        early_exit_min_reduction: float=0.0,
        early_exit_min_absolute_error: float=0.0,
        enable_bold_updates: bool=False,
        _skip_initialize: bool=False,
    ) -> None:
        """ If _skip_initialize is True, all other constructor arguments are ignored """
        if _skip_initialize:
            return
        # Print information for every iteration?
        self.verbose: bool = verbose
        # Whether the optimizer should record debugging stats such as the optimized values, residual,
        # jacobian, etc. computed at each iteration of the optimization.
        self.debug_stats: bool = debug_stats
        # Check derivatives for consistency.  This computes the numerical jacobian of the residual, and
        # verifies that it matches the jacobian computed by the linearization function.  It also verifies
        # that the Hessian and RHS computed by the linearization function match J^T * J and J^T * b
        self.check_derivatives: bool = check_derivatives
        # Whether the optimizer should compute jacobians.  Required for check_derivatives, and for
        # computing linear error at each step.
        self.include_jacobians: bool = include_jacobians
        # If true, will perform additional sanity checks while optimizing which may be expensive.  This
        # uses additional compute but not additional memory except for logging.
        self.debug_checks: bool = debug_checks
        # Damping value (lambda) on the first iteration of the LM loop
        self.initial_lambda: float = initial_lambda
        # Smallest allowed value for lambda
        self.lambda_lower_bound: float = lambda_lower_bound
        # Largest allowed value for lambda
        self.lambda_upper_bound: float = lambda_upper_bound
        # Method for updating lambda, see lambda_update_type_t
        self.lambda_update_type: lambda_update_type_t = lambda_update_type_t._default() if lambda_update_type is None else lambda_update_type
        # [Used if lambda_update_type == STATIC] Factor greater than one to multiply by lambda
        self.lambda_up_factor: float = lambda_up_factor
        # [Used if lambda_update_type == STATIC] Factor less than one to multiply by lambda
        self.lambda_down_factor: float = lambda_down_factor
        # [Used if lambda_update_type == DYNAMIC] Lambda update parameter beta.  This is the initial
        # value of nu, and scales the update for lambda.  Recommended value is 2
        self.dynamic_lambda_update_beta: float = dynamic_lambda_update_beta
        # [Used if lambda_update_type == DYNAMIC] Lambda update parameter gamma.  This is the factor by
        # which lambda is reduced when the gain is >= 1.  Recommended value is 3
        self.dynamic_lambda_update_gamma: float = dynamic_lambda_update_gamma
        # [Used if lambda_update_type == DYNAMIC] Exponent in the power law for the updated lambda,
        # should be an odd positive integer. Recommended value is 3
        self.dynamic_lambda_update_p: int = dynamic_lambda_update_p
        # Damp the Hessian adaptively based on the values on its diagonal?
        self.use_diagonal_damping: bool = use_diagonal_damping
        # Damp the Hessian with a constant lambda?
        self.use_unit_damping: bool = use_unit_damping
        # Use the elementwise max of the diagonal over all past iterations, instead
        # of the current diagonal? (Only used when use_diagonal_damping is turned on)
        self.keep_max_diagonal_damping: bool = keep_max_diagonal_damping
        # Initial values of the diagonal when using keep_max_diagonal_damping (i.e.
        # if the max for a particular element on the diagonal is less than
        # diagonal_damping_min, that element of the diagonal is set to
        # diagonal_damping_min)
        self.diagonal_damping_min: float = diagonal_damping_min
        # Max number of LM iterations to run in an optimization
        self.iterations: int = iterations
        # Early exit from the optimization if the absolute value of the relative reduction is
        # less than this amount
        self.early_exit_min_reduction: float = early_exit_min_reduction
        # Early exit from the optimization if the error (i.e. 0.5 * residual.dot(residual)) is less than
        # this amount
        self.early_exit_min_absolute_error: float = early_exit_min_absolute_error
        # Allow uphill movements in the optimization?
        self.enable_bold_updates: bool = enable_bold_updates

    @staticmethod
    def from_all_fields(
        verbose: bool,
        debug_stats: bool,
        check_derivatives: bool,
        include_jacobians: bool,
        debug_checks: bool,
        initial_lambda: float,
        lambda_lower_bound: float,
        lambda_upper_bound: float,
        lambda_update_type: lambda_update_type_t,
        lambda_up_factor: float,
        lambda_down_factor: float,
        dynamic_lambda_update_beta: float,
        dynamic_lambda_update_gamma: float,
        dynamic_lambda_update_p: int,
        use_diagonal_damping: bool,
        use_unit_damping: bool,
        keep_max_diagonal_damping: bool,
        diagonal_damping_min: float,
        iterations: int,
        early_exit_min_reduction: float,
        early_exit_min_absolute_error: float,
        enable_bold_updates: bool,
    ) -> "optimizer_params_t":
        return optimizer_params_t(
            verbose=verbose,
            debug_stats=debug_stats,
            check_derivatives=check_derivatives,
            include_jacobians=include_jacobians,
            debug_checks=debug_checks,
            initial_lambda=initial_lambda,
            lambda_lower_bound=lambda_lower_bound,
            lambda_upper_bound=lambda_upper_bound,
            lambda_update_type=lambda_update_type,
            lambda_up_factor=lambda_up_factor,
            lambda_down_factor=lambda_down_factor,
            dynamic_lambda_update_beta=dynamic_lambda_update_beta,
            dynamic_lambda_update_gamma=dynamic_lambda_update_gamma,
            dynamic_lambda_update_p=dynamic_lambda_update_p,
            use_diagonal_damping=use_diagonal_damping,
            use_unit_damping=use_unit_damping,
            keep_max_diagonal_damping=keep_max_diagonal_damping,
            diagonal_damping_min=diagonal_damping_min,
            iterations=iterations,
            early_exit_min_reduction=early_exit_min_reduction,
            early_exit_min_absolute_error=early_exit_min_absolute_error,
            enable_bold_updates=enable_bold_updates,
        )

    @staticmethod
    def _skytype_meta() -> T.Dict[str, str]:
        return dict(
            type="struct",
            package="sym",
            name="optimizer_params_t",
        )

    @classmethod
    def _default(cls) -> "optimizer_params_t":
        return cls()

    def __repr__(self) -> str:
        return "optimizer_params_t({})".format(
            ", ".join("{}={}".format(name, repr(getattr(self, name))) for name in self.__slots__))

    def __eq__(self, other: object) -> bool:
        if not isinstance(other, optimizer_params_t):
            return NotImplemented
        return (
            (self.verbose==other.verbose) and
            (self.debug_stats==other.debug_stats) and
            (self.check_derivatives==other.check_derivatives) and
            (self.include_jacobians==other.include_jacobians) and
            (self.debug_checks==other.debug_checks) and
            (self.initial_lambda==other.initial_lambda) and
            (self.lambda_lower_bound==other.lambda_lower_bound) and
            (self.lambda_upper_bound==other.lambda_upper_bound) and
            (self.lambda_update_type==other.lambda_update_type) and
            (self.lambda_up_factor==other.lambda_up_factor) and
            (self.lambda_down_factor==other.lambda_down_factor) and
            (self.dynamic_lambda_update_beta==other.dynamic_lambda_update_beta) and
            (self.dynamic_lambda_update_gamma==other.dynamic_lambda_update_gamma) and
            (self.dynamic_lambda_update_p==other.dynamic_lambda_update_p) and
            (self.use_diagonal_damping==other.use_diagonal_damping) and
            (self.use_unit_damping==other.use_unit_damping) and
            (self.keep_max_diagonal_damping==other.keep_max_diagonal_damping) and
            (self.diagonal_damping_min==other.diagonal_damping_min) and
            (self.iterations==other.iterations) and
            (self.early_exit_min_reduction==other.early_exit_min_reduction) and
            (self.early_exit_min_absolute_error==other.early_exit_min_absolute_error) and
            (self.enable_bold_updates==other.enable_bold_updates)
        )
    # Disallow hashing for python struct lcmtypes.
    __hash__ = None  # type: ignore[assignment]

    def encode(self) -> bytes:
        buf = BytesIO()
        buf.write(optimizer_params_t._get_packed_fingerprint())
        self._encode_one(buf)
        return buf.getvalue()

    def _encode_one(self, buf: T.BinaryIO) -> None:
        buf.write(optimizer_params_t._CACHED_STRUCT_0.pack(self.verbose, self.debug_stats, self.check_derivatives, self.include_jacobians, self.debug_checks, self.initial_lambda, self.lambda_lower_bound, self.lambda_upper_bound))
        if hasattr(self.lambda_update_type, '_get_packed_fingerprint'):
            assert self.lambda_update_type._get_packed_fingerprint() == lambda_update_type_t._get_packed_fingerprint()
        else:
            assert self.lambda_update_type._get_hash_recursive([]) == lambda_update_type_t._get_hash_recursive([])
        self.lambda_update_type._encode_one(buf)
        buf.write(optimizer_params_t._CACHED_STRUCT_1.pack(self.lambda_up_factor, self.lambda_down_factor, self.dynamic_lambda_update_beta, self.dynamic_lambda_update_gamma, self.dynamic_lambda_update_p, self.use_diagonal_damping, self.use_unit_damping, self.keep_max_diagonal_damping, self.diagonal_damping_min, self.iterations, self.early_exit_min_reduction, self.early_exit_min_absolute_error, self.enable_bold_updates))

    @staticmethod
    def decode(data: T.Union[bytes, T.BinaryIO]) -> "optimizer_params_t":
        # NOTE(eric): This function can technically accept either a BinaryIO or
        # anything that supports the C++ Buffer Protocol,
        # which is unspecifiable in type hints.

        if hasattr(data, "read"):
            # NOTE(eric): mypy isn't able to figure out the hasattr check
            buf = T.cast(T.BinaryIO, data)
        else:
            buf = BytesIO(T.cast(bytes, data))

        if buf.read(8) != optimizer_params_t._get_packed_fingerprint():
            raise ValueError("Decode error")
        return optimizer_params_t._decode_one(buf)

    @staticmethod
    def _decode_one(buf: T.BinaryIO) -> "optimizer_params_t":
        self = optimizer_params_t(_skip_initialize=True)
        self.verbose = bool(optimizer_params_t._CACHED_STRUCT_2.unpack(buf.read(1))[0])
        self.debug_stats = bool(optimizer_params_t._CACHED_STRUCT_2.unpack(buf.read(1))[0])
        self.check_derivatives = bool(optimizer_params_t._CACHED_STRUCT_2.unpack(buf.read(1))[0])
        self.include_jacobians = bool(optimizer_params_t._CACHED_STRUCT_2.unpack(buf.read(1))[0])
        self.debug_checks = bool(optimizer_params_t._CACHED_STRUCT_2.unpack(buf.read(1))[0])
        self.initial_lambda, self.lambda_lower_bound, self.lambda_upper_bound = optimizer_params_t._CACHED_STRUCT_3.unpack(buf.read(24))
        self.lambda_update_type = lambda_update_type_t._decode_one(buf)
        self.lambda_up_factor, self.lambda_down_factor, self.dynamic_lambda_update_beta, self.dynamic_lambda_update_gamma, self.dynamic_lambda_update_p = optimizer_params_t._CACHED_STRUCT_4.unpack(buf.read(36))
        self.use_diagonal_damping = bool(optimizer_params_t._CACHED_STRUCT_2.unpack(buf.read(1))[0])
        self.use_unit_damping = bool(optimizer_params_t._CACHED_STRUCT_2.unpack(buf.read(1))[0])
        self.keep_max_diagonal_damping = bool(optimizer_params_t._CACHED_STRUCT_2.unpack(buf.read(1))[0])
        self.diagonal_damping_min, self.iterations, self.early_exit_min_reduction, self.early_exit_min_absolute_error = optimizer_params_t._CACHED_STRUCT_5.unpack(buf.read(28))
        self.enable_bold_updates = bool(optimizer_params_t._CACHED_STRUCT_2.unpack(buf.read(1))[0])
        return self

    @staticmethod
    def _get_hash_recursive(parents: T.List[T.Type]) -> int:
        if optimizer_params_t in parents: return 0
        newparents = parents + [optimizer_params_t]
        tmphash = (0xb9b0fa3079b1e51+ lambda_update_type_t._get_hash_recursive(newparents)) & 0xffffffffffffffff
        tmphash = (((tmphash<<1)&0xffffffffffffffff)  + (tmphash>>63)) & 0xffffffffffffffff
        return tmphash

    _packed_fingerprint: T.Optional[bytes] = None

    @staticmethod
    def _get_packed_fingerprint() -> bytes:
        if optimizer_params_t._packed_fingerprint is None:
            optimizer_params_t._packed_fingerprint = struct.pack(">Q", optimizer_params_t._get_hash_recursive([]))
        return optimizer_params_t._packed_fingerprint

    def deepcopy(self, **kwargs: T.Any) -> "optimizer_params_t":
        """
        Deep copy of this LCM type

        Returns a copy w/ members specified by kwargs replaced with new values specified by kwargs.
        """
        result = copy.deepcopy(self)
        for key in kwargs:
            if not hasattr(result, key):
                raise KeyError("Type optimizer_params_t does not have attribute: " + str(key))
            setattr(result, key, kwargs[key])
        return result

    _CACHED_STRUCT_0 = struct.Struct(">bbbbbddd")
    _CACHED_STRUCT_1 = struct.Struct(">ddddibbbdiddb")
    _CACHED_STRUCT_2 = struct.Struct("b")
    _CACHED_STRUCT_3 = struct.Struct(">ddd")
    _CACHED_STRUCT_4 = struct.Struct(">ddddi")
    _CACHED_STRUCT_5 = struct.Struct(">didd")
