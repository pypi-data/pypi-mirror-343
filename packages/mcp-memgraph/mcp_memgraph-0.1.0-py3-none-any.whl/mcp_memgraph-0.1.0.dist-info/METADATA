Metadata-Version: 2.4
Name: mcp-memgraph
Version: 0.1.0
Summary: MCP integration and utilities for Memgraph MCP server
Project-URL: Homepage, https://github.com/memgraph/ai-toolkit
Project-URL: Source, https://github.com/memgraph/ai-toolkit/tree/main/integrations/mcp-memgraph
Project-URL: Issues, https://github.com/memgraph/ai-toolkit/issues
Author-email: antejavor <ante.javor@memgraph.io>
License: MIT
License-File: LICENSE
Keywords: graph,integration,mcp,memgraph,toolkit
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.10
Requires-Dist: httpx>=0.28.1
Requires-Dist: mcp[cli]>=1.3.0
Requires-Dist: memgraph-toolbox
Requires-Dist: neo4j>=5.28.1
Provides-Extra: test
Requires-Dist: anthropic; extra == 'test'
Requires-Dist: mcp[cli]>=1.3.0; extra == 'test'
Requires-Dist: pytest-asyncio>=0.20.3; extra == 'test'
Requires-Dist: pytest>=8.3.5; extra == 'test'
Requires-Dist: python-dotenv>=1.0.1; extra == 'test'
Description-Content-Type: text/markdown

# ğŸš€ Memgraph MCP Server

Memgraph MCP Server is a lightweight server implementation of the Model Context Protocol (MCP) designed to connect Memgraph with LLMs.

![mcp-server](./mcp-server.png)

## âš¡ Quick start

> ğŸ“¹ [Memgraph MCP Server Quick Start video](https://www.youtube.com/watch?v=0Tjw5QWj_qY)

### 1. Run Memgraph MCP Server

1. Install [`uv`](https://docs.astral.sh/uv/getting-started/installation/) and create `venv` with `uv venv`. Activate virtual environment with `.venv\Scripts\activate`.
2. Install dependencies: `uv add "mcp[cli]" httpx`
3. Run Memgraph MCP server: `uv run server.py`.

### 2. Run MCP Client

1. Install [Claude for Desktop](https://claude.ai/download).
2. Add the Memgraph server to Claude config:

**MacOS/Linux**

```
code ~/Library/Application\ Support/Claude/claude_desktop_config.json
```

**Windows**

```
code $env:AppData\Claude\claude_desktop_config.json
```

Example config:

```
{
    "mcpServers": {
      "mpc-memgraph": {
        "command": "/Users/katelatte/.local/bin/uv",
        "args": [
            "--directory",
            "/Users/katelatte/projects/mcp-memgraph",
            "run",
            "server.py"
        ]
     }
   }
}
```

> [!NOTE]  
> You may need to put the full path to the uv executable in the command field. You can get this by running `which uv` on MacOS/Linux or `where uv` on Windows. Make sure you pass in the absolute path to your server.

### 3. Chat with the database

1. Run Memgraph MAGE:
   ```
   docker run -p 7687:7687 memgraph/memgraph-mage --schema-info-enabled=True
   ```
   The `--schema-info-enabled` configuration setting is set to `True` to allow LLM to run `SHOW SCHEMA INFO` query.
2. Open Claude Desktop and see the Memgraph tools and resources listed. Try it out! (You can load dummy data from [Memgraph Lab](https://memgraph.com/docs/data-visualization) Datasets)

## ğŸ”§Tools

### run_query()

Run a Cypher query against Memgraph.

## ğŸ—ƒï¸ Resources

### get_schema()

Get Memgraph schema information (prerequisite: `--schema-info-enabled=True`).

## ğŸ—ºï¸ Roadmap

The Memgraph MCP Server is just at its beginnings. We're actively working on expanding its capabilities and making it even easier to integrate Memgraph into modern AI workflows.
