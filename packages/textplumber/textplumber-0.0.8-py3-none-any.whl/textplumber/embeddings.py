"""Extract text embedding features."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/80_embeddings.ipynb.

# %% ../nbs/80_embeddings.ipynb 3
from __future__ import annotations
from sklearn.base import BaseEstimator, TransformerMixin
from .store import TextFeatureStore
from model2vec import StaticModel
import numpy as np
from fastcore.basics import patch

# %% auto 0
__all__ = ['Model2VecEmbedder']

# %% ../nbs/80_embeddings.ipynb 4
class Model2VecEmbedder(BaseEstimator, TransformerMixin):
	""" Sci-kit Learn pipeline component to generate embeddings using Model2Vec. """
	def __init__(self, 
                feature_store: TextFeatureStore, # the feature store to use - this should be the same feature store used in the SpacyPreprocessor component
				model_name:str = 'minishlab/potion-base-8M', # the model name to use
				batch_size:int = 5000 # batch size for encoding text
				):
		self.feature_store = feature_store
		self.model_name = model_name
		self.model_ = StaticModel.from_pretrained(self.model_name)
		self.batch_size = batch_size


# %% ../nbs/80_embeddings.ipynb 5
@patch
def fit(self:Model2VecEmbedder, X, y=None):
	""" Fit is implemented, but does nothing. """
	return self

# %% ../nbs/80_embeddings.ipynb 6
@patch
def transform(self:Model2VecEmbedder, X):
	""" Generate embeddings for the texts using Model2Vec. 
	If the embeddings are already in the feature store, they are used instead of recomputing them. Processing is done in batches of 
	1000 texts to avoid memory issues. """
	embeddings = self.feature_store.get_embeddings_from_texts(X)
	if any(x is None for x in embeddings):
		embeddings = []
		for i in range(0, len(X), 5000):
			X_batch = X[i:i+5000]
			embeddings_batch = self.model_.encode(X_batch)
			embeddings_batch = np.array(embeddings_batch, dtype=np.double) # returning as floats seemed to be causing issues with kmeans pipeline component
			embeddings.append(embeddings_batch)
		embeddings = np.concatenate(embeddings, axis=0)
		self.feature_store.update_embeddings(X, embeddings)
	else:
		# all the embeddings are already in the feature store so no need to reprocess
		pass
	return embeddings



# %% ../nbs/80_embeddings.ipynb 7
@patch
def get_feature_names_out(self:Model2VecEmbedder, input_features=None):
	""" Get the feature names out from the model. """
	return [f'emb_{i}' for i in range(self.model_.dim)]
