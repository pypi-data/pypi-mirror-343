{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Intro","text":"<p><code>mocker-db</code> is a python module that contains mock vector database like solution built around python dictionary data type. It contains methods necessary to interact with this 'database', embed, search and persist.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install mocker-db\n</code></pre>"},{"location":"cli/","title":"Cli","text":"<pre><code>mockerdb --help\n</code></pre> <pre><code>Usage: mockerdb [OPTIONS] COMMAND [ARGS]...\n\n  Package Auto Assembler CLI tool.\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  init-config  Initialize config file for api\n</code></pre> <p>MockerDB API can be run through <code>package-auto-assembler</code> functionality using the following command:</p> <pre><code>paa run-api-routes --package mocker_db\n</code></pre> <p>To change default config values, a file named <code>.mockerdb.api.config</code> needs to be located in path the <code>paa</code> command is run. By initializing config, you can see defailt config and edit it.</p> <pre><code>mockerdb init-config  --help\n</code></pre> <pre><code>Usage: mockerdb init-config [OPTIONS]\n\n  Initialize config file for api\n\nOptions:\n  --help  Show this message and exit.\n</code></pre>"},{"location":"description/","title":"Description","text":"<pre><code>from mocker_db import MockerDB, MockerConnector, SentenceTransformerEmbedder\n</code></pre>"},{"location":"description/#1-inserting-values-into-the-database","title":"1. Inserting values into the database","text":"<p>MockerDB can be used as ephemeral database where everything is saved in memory, but also can be persisted in one file for the database and another for embeddings storage.</p> <p>Embedder is set to sentence_transformer by default and processed locally, custom embedders that connect to an api or use other open source models could be used as long as they have the same interface. </p> <pre><code># Initialization\nhandler = MockerDB(\n    # optional\n    embedder_params = {'model_name_or_path' : 'paraphrase-multilingual-mpnet-base-v2',\n                        'processing_type' : 'batch',\n                        'tbatch_size' : 500},\n    similarity_search_type = 'linear_torch',\n    use_embedder = True,\n    embedder = SentenceTransformerEmbedder,\n    persist = True\n)\n# Initialize empty database\nhandler.establish_connection(\n    # optional for persist\n    file_path = \"./mock_persist\",\n    embs_file_path = \"./mock_embs_persist\",\n)\n</code></pre> <pre><code>sentences = [\n    \"The cat slept.\",\n    \"It rained today.\",\n    \"She smiled gently.\",\n    \"Books hold knowledge.\",\n    \"The sun set behind the mountains, casting a golden glow over the valley.\",\n    \"He quickly realized that time was slipping away, and he needed to act fast.\",\n    \"The concert was an unforgettable experience, filled with laughter and joy.\",\n    \"Despite the challenges, they managed to build a beautiful home together.\",\n    \"As the wind howled through the ancient trees, scattering leaves and whispering secrets of the forest, she stood there, gazing up at the endless expanse of stars, feeling both infinitely small and profoundly connected to the universe.\",\n    \"While the project seemed daunting at first, requiring countless hours of research, planning, and execution, the team worked tirelessly, motivated by their shared goal of creating something truly remarkable and innovative in their field.\",\n    \"In the bustling city streets, amidst the constant hum of traffic and chatter, he found himself contemplating life's mysteries, pondering the choices that had brought him to this very moment and wondering where the path ahead would lead.\",\n    \"The conference was a gathering of minds from around the globe, each participant bringing their unique perspectives and insights to the table, fostering a vibrant exchange of ideas that would shape the future of their respective fields for years to come.\"\n]\n\n# Insert Data\nvalues_list = [\n    {'text' : t, 'n_words' : len(t.split())} for t in sentences\n]\nhandler.insert_values(values_list, \"text\")\nprint(f\"Items in the database {len(handler.data)}\")\n</code></pre> <pre><code>Items in the database 12\n</code></pre>"},{"location":"description/#2-searching-and-retrieving-values-from-the-database","title":"2. Searching and retrieving values from the database","text":"<p>There are multiple options for search which could be used together or separately:</p> <ul> <li>simple filter</li> <li>filter with keywords</li> <li>llm filter</li> <li>search based on similarity</li> </ul>"},{"location":"description/#get-all-keys","title":"get all keys","text":"<pre><code>results = handler.search_database(\n    query = \"cat\",\n    filter_criteria = {\n        \"n_words\" : 3,\n    }\n)\nprint([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])\n</code></pre> <pre><code>[{'text': 'The cat slept....', 'n_words': '3...'}, {'text': 'She smiled gently....', 'n_words': '3...'}, {'text': 'It rained today....', 'n_words': '3...'}, {'text': 'Books hold knowledge....', 'n_words': '3...'}]\n</code></pre>"},{"location":"description/#get-all-keys-with-keywords-search","title":"get all keys with keywords search","text":"<pre><code>results = handler.search_database(\n    # when keyword key is provided filter is used to pass keywords\n    filter_criteria = {\n        \"text\" : [\"sun\"],\n    },\n    keyword_check_keys = ['text'],\n    # percentage of filter keyword allowed to be different\n    keyword_check_cutoff = 1,\n    return_keys_list=['text']\n)\nprint([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])\n</code></pre> <pre><code>[{'text': 'The sun set behind the mountai...'}]\n</code></pre>"},{"location":"description/#get-all-key-n_words","title":"get all key - n_words","text":"<pre><code>results = handler.search_database(\n    query = \"cat\",\n    filter_criteria = {\n        \"n_words\" : 3,\n    },\n    return_keys_list=[\"-n_words\"])\nprint([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])\n</code></pre> <pre><code>[{'text': 'The cat slept....'}, {'text': 'She smiled gently....'}, {'text': 'It rained today....'}, {'text': 'Books hold knowledge....'}]\n</code></pre>"},{"location":"description/#get-all-keys-distance","title":"get all keys + distance","text":"<pre><code>results = handler.search_database(\n    query = \"cat slept\",\n    filter_criteria = {\n        \"n_words\" : 3,\n    },\n    return_keys_list=[\"+&amp;distance\"]\n)\nprint([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])\n</code></pre> <pre><code>[{'text': 'The cat slept....', 'n_words': '3...', '&amp;distance': '0.9757655893784214...'}, {'text': 'She smiled gently....', 'n_words': '3...', '&amp;distance': '0.25537100167603033...'}, {'text': 'It rained today....', 'n_words': '3...', '&amp;distance': '0.049663180663929454...'}, {'text': 'Books hold knowledge....', 'n_words': '3...', '&amp;distance': '0.011214834039176086...'}]\n</code></pre>"},{"location":"description/#get-distance","title":"get distance","text":"<pre><code>results = handler.search_database(\n    query = \"cat slept\",\n    filter_criteria = {\n        \"n_words\" : 3,\n    },\n    return_keys_list=[\"&amp;distance\"]\n)\nprint([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])\n</code></pre> <pre><code>[{'&amp;distance': '0.9757655893784214...'}, {'&amp;distance': '0.25537100167603033...'}, {'&amp;distance': '0.049663180663929454...'}, {'&amp;distance': '0.011214834039176086...'}]\n</code></pre>"},{"location":"description/#get-all-keys-embeddings","title":"get all keys + embeddings","text":"<pre><code>results = handler.search_database(\n    query = \"cat slept\",\n    filter_criteria = {\n        \"n_words\" : 3,\n    },\n    return_keys_list=[\"+embedding\"]\n)\nprint([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])\n</code></pre> <pre><code>[{'text': 'The cat slept....', 'n_words': '3...', 'embedding': '[-3.86438444e-02  1.23167984e-...'}, {'text': 'She smiled gently....', 'n_words': '3...', 'embedding': '[-2.46711876e-02  2.37020180e-...'}, {'text': 'It rained today....', 'n_words': '3...', 'embedding': '[-1.35887727e-01 -2.52719879e-...'}, {'text': 'Books hold knowledge....', 'n_words': '3...', 'embedding': '[ 6.20863438e-02  1.13785945e-...'}]\n</code></pre>"},{"location":"description/#get-embeddings","title":"get embeddings","text":"<pre><code>results = handler.search_database(\n    query = \"cat slept\",\n    filter_criteria = {\n        \"n_words\" : 3,\n    },\n    return_keys_list=[\"embedding\"]\n)\nprint([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])\n\n</code></pre> <pre><code>[{'embedding': '[-3.86438444e-02  1.23167984e-...'}, {'embedding': '[-2.46711876e-02  2.37020180e-...'}, {'embedding': '[-1.35887727e-01 -2.52719879e-...'}, {'embedding': '[ 6.20863438e-02  1.13785945e-...'}]\n</code></pre>"},{"location":"description/#get-embeddings-and-embedded-field","title":"get embeddings and embedded field","text":"<pre><code>results = handler.search_database(\n    query = \"cat slept\",\n    filter_criteria = {\n        \"n_words\" : 3,\n    },\n    return_keys_list=[\"embedding\", \"+&amp;embedded_field\"]\n)\nprint([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])\n\n</code></pre> <pre><code>[{'embedding': '[-3.86438444e-02  1.23167984e-...', '&amp;embedded_field': 'text...'}, {'embedding': '[-2.46711876e-02  2.37020180e-...', '&amp;embedded_field': 'text...'}, {'embedding': '[-1.35887727e-01 -2.52719879e-...', '&amp;embedded_field': 'text...'}, {'embedding': '[ 6.20863438e-02  1.13785945e-...', '&amp;embedded_field': 'text...'}]\n</code></pre>"},{"location":"description/#get-all-keys-with-llm-search","title":"get all keys with llm search","text":"<p>Ollama</p> <pre><code>import logging\nlogging.disable(logging.INFO)\n\n# Initialization\nhandler = MockerDB(\n    # optional\n    persist = True,\n    llm_conn_params = {\n\n        'llm_h_type' : 'OllamaConn',\n        'llm_h_params' : {\n            'connection_string' : 'http://127.0.0.1:11434',\n            'model_name' : 'llama3.1:latest'\n        }\n\n    }\n)\n# Initialize empty database\nhandler.establish_connection(\n    # optional for persist\n    file_path = \"./mock_persist\",\n    embs_file_path = \"./mock_embs_persist\",\n)\n\nresults = await handler.search_database_async(\n    llm_search_keys=['text'],\n    filter_criteria = {\n        \"text\" : [\"cat\", \"nature\"],\n    },\n    return_keys_list=[\"+&amp;cats\"],\n    ignore_cats_cache=False\n)\nprint([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])\n</code></pre> <pre><code>[{'text': 'The cat slept....', 'n_words': '3...', '&amp;cats': \"{'text': ['cat']}...\"}, {'text': 'The sun set behind the mountai...', 'n_words': '13...', '&amp;cats': \"{'text': ['nature']}...\"}, {'text': 'As the wind howled through the...', 'n_words': '37...', '&amp;cats': \"{'text': ['nature']}...\"}]\n</code></pre> <pre><code>handler.cats\n</code></pre> <pre><code>{'The cat slept.': {1: ['cat'], 0: ['nature']},\n 'It rained today.': {1: [], 0: ['cat', 'nature']},\n 'She smiled gently.': {1: [], 0: ['cat', 'nature']},\n 'Books hold knowledge.': {1: [], 0: ['cat', 'nature']},\n 'The sun set behind the mountains, casting a golden glow over the valley.': {1: ['nature'],\n  0: ['cat']},\n 'He quickly realized that time was slipping away, and he needed to act fast.': {1: [],\n  0: ['cat', 'nature']},\n 'The concert was an unforgettable experience, filled with laughter and joy.': {1: [],\n  0: ['cat', 'nature']},\n 'Despite the challenges, they managed to build a beautiful home together.': {1: [],\n  0: ['cat', 'nature']},\n 'As the wind howled through the ancient trees, scattering leaves and whispering secrets of the forest, she stood there, gazing up at the endless expanse of stars, feeling both infinitely small and profoundly connected to the universe.': {1: ['nature'],\n  0: ['cat']},\n 'While the project seemed daunting at first, requiring countless hours of research, planning, and execution, the team worked tirelessly, motivated by their shared goal of creating something truly remarkable and innovative in their field.': {1: [],\n  0: ['cat', 'nature']},\n \"In the bustling city streets, amidst the constant hum of traffic and chatter, he found himself contemplating life's mysteries, pondering the choices that had brought him to this very moment and wondering where the path ahead would lead.\": {1: [],\n  0: ['cat', 'nature']},\n 'The conference was a gathering of minds from around the globe, each participant bringing their unique perspectives and insights to the table, fostering a vibrant exchange of ideas that would shape the future of their respective fields for years to come.': {1: [],\n  0: ['cat', 'nature']}}\n</code></pre> <p>OpenAI</p> <pre><code>import logging\nlogging.disable(logging.INFO)\n\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv(\"../../credentials\")\n\n# Initialization\nhandler = MockerDB(\n    # optional\n    persist = True,\n    llm_conn_params = {\n\n        'llm_h_type' : 'OpenAIConn',\n        'llm_h_params' : {\n            'model_name' : 'gpt-4o-mini',\n            'env_mapping' : {\n                'api_key' : \"OPENAI_KEY\"\n            }\n        }\n\n    }\n)\n# Initialize empty database\nhandler.establish_connection(\n    # optional for persist\n    file_path = \"./mock_persist\",\n    embs_file_path = \"./mock_embs_persist\",\n)\n\nresults = await handler.search_database_async(\n    llm_search_keys=['text'],\n    filter_criteria = {\n        \"text\" : [\"cat\", \"nature\"],\n    }\n)\nprint([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])\n</code></pre> <pre><code>[{'text': 'The cat slept....', 'n_words': '3...'}, {'text': 'The sun set behind the mountai...', 'n_words': '13...'}, {'text': 'As the wind howled through the...', 'n_words': '37...'}]\n</code></pre>"},{"location":"description/#3-removing-values-from-the-database","title":"3. Removing values from the database","text":"<pre><code>print(f\"Items in the database {len(handler.data)}\")\nhandler.remove_from_database(filter_criteria = {\"n_words\" : 11})\nprint(f\"Items left in the database {len(handler.data)}\")\n\n</code></pre> <pre><code>Items in the database 14\nItems left in the database 12\n</code></pre>"},{"location":"description/#4-embeding-text","title":"4 Embeding text","text":"<pre><code>results = handler.embed_texts(\n    texts = [\n    \"Short. Variation 1: Short.\",\n    \"Another medium-length example, aiming to test the variability in processing different lengths of text inputs. Variation 2: processing lengths medium-length example, in inputs. to variability aiming test of text different the Another\"\n  ]\n)\n\nprint(str(results)[0:300] + \"...\")\n</code></pre> <pre><code>{'embeddings': [[0.04973424971103668, -0.43570247292518616, -0.014545125886797905, -0.03648979589343071, -0.04165348783135414, -0.04544278606772423, -0.07025150209665298, 0.10043243318796158, -0.20846229791641235, 0.15596869587898254, 0.11489829421043396, -0.13442179560661316, -0.02425091527402401, ...\n</code></pre>"},{"location":"description/#5-using-mockerdb-api","title":"5. Using MockerDB API","text":"<p>Remote Mocker can be used via very similar methods to the local one.</p> <pre><code># Initialization\nhandler = MockerDB(\n    skip_post_init=True\n)\n# Initialize empty database\nhandler.establish_connection(\n     # optional for connecting to api\n    connection_details = {\n        'base_url' : \"http://localhost:8000/mocker-db\"\n    }\n)\n</code></pre> <pre><code>sentences = [\n    \"The cat slept.\",\n    \"It rained today.\",\n    \"She smiled gently.\",\n    \"Books hold knowledge.\",\n    \"The sun set behind the mountains, casting a golden glow over the valley.\",\n    \"He quickly realized that time was slipping away, and he needed to act fast.\",\n    \"The concert was an unforgettable experience, filled with laughter and joy.\",\n    \"Despite the challenges, they managed to build a beautiful home together.\",\n    \"As the wind howled through the ancient trees, scattering leaves and whispering secrets of the forest, she stood there, gazing up at the endless expanse of stars, feeling both infinitely small and profoundly connected to the universe.\",\n    \"While the project seemed daunting at first, requiring countless hours of research, planning, and execution, the team worked tirelessly, motivated by their shared goal of creating something truly remarkable and innovative in their field.\",\n    \"In the bustling city streets, amidst the constant hum of traffic and chatter, he found himself contemplating life's mysteries, pondering the choices that had brought him to this very moment and wondering where the path ahead would lead.\",\n    \"The conference was a gathering of minds from around the globe, each participant bringing their unique perspectives and insights to the table, fostering a vibrant exchange of ideas that would shape the future of their respective fields for years to come.\"\n]\n\n# Insert Data\nvalues_list = [\n    {'text' : t, 'n_words' : len(t.split())} for t in sentences\n]\nhandler.insert_values(values_list, \"text\")\n</code></pre> <pre><code>{'status': 'success', 'message': ''}\n</code></pre> <p>MockerAPI has multiple handlers stored in memory at a time, they can be displayed with number of items and memory estimate.</p> <pre><code>handler.show_handlers()\n</code></pre> <pre><code>{'results': [{'handler': 'default',\n   'items': 12,\n   'memory_usage': 1.4748001098632812}],\n 'status': 'success',\n 'message': '',\n 'handlers': ['default'],\n 'items': [12],\n 'memory_usage': [1.4748001098632812]}\n</code></pre> <pre><code>results = handler.search_database(\n    query = \"cat\",\n    filter_criteria = {\n        \"n_words\" : 3,\n    }\n)\n\nresults\n</code></pre> <pre><code>{'status': 'success',\n 'message': '',\n 'handler': 'default',\n 'results': [{'text': 'The cat slept.', 'n_words': 3},\n  {'text': 'Books hold knowledge.', 'n_words': 3},\n  {'text': 'It rained today.', 'n_words': 3},\n  {'text': 'She smiled gently.', 'n_words': 3}]}\n</code></pre> <pre><code>results = handler.embed_texts(\n    texts = [\n    \"Short. Variation 1: Short.\",\n    \"Another medium-length example, aiming to test the variability in processing different lengths of text inputs. Variation 2: processing lengths medium-length example, in inputs. to variability aiming test of text different the Another\"\n  ],\n    # optional\n    embedding_model = \"intfloat/multilingual-e5-base\"\n)\n\nprint(str(results)[0:500] + \"...\")\n</code></pre> <pre><code>{'status': 'success', 'message': '', 'handler': 'cache_mocker_intfloat_multilingual-e5-base', 'embedding_model': 'intfloat/multilingual-e5-base', 'embeddings': [[-0.021023569628596306, 0.03461984172463417, -0.013103404082357883, 0.030711326748132706, 0.023395603522658348, -0.040545400232076645, -0.01580517739057541, -0.026828577741980553, 0.015833470970392227, 0.017637528479099274, 0.0008703444618731737, -0.011133708991110325, 0.11296682059764862, 0.015158110298216343, -0.04669041559100151, -0.0...\n</code></pre> <pre><code>handler.show_handlers()\n</code></pre> <pre><code>{'results': [{'handler': 'default',\n   'items': 12,\n   'memory_usage': 1.4762191772460938},\n  {'handler': 'cache_mocker_intfloat_multilingual-e5-base',\n   'items': 2,\n   'memory_usage': 1.4075469970703125}],\n 'status': 'success',\n 'message': '',\n 'handlers': ['default', 'cache_mocker_intfloat_multilingual-e5-base'],\n 'items': [12, 2],\n 'memory_usage': [1.4762191772460938, 1.4075469970703125]}\n</code></pre>"},{"location":"flow/","title":"Flow","text":""},{"location":"release-notes/","title":"Release notes","text":""},{"location":"release-notes/#030","title":"0.3.0","text":"<pre><code>- initial version of cache of llm classification performed during llm filtering step\n\n- integrating ollama and openai llm handlers for llm filter feature\n\n- upgrading older version of attrs to attrsx\n</code></pre>"},{"location":"release-notes/#027","title":"0.2.7","text":"<pre><code>- minor fixes for initial llm filter\n\n- separate async search_database_async method\n</code></pre>"},{"location":"release-notes/#026","title":"0.2.6","text":"<pre><code>- cosine similarity with torch\n\n- adding missing inputs for remote mocker in search_database method\n</code></pre>"},{"location":"release-notes/#025","title":"0.2.5","text":"<pre><code>- simple cli for initializing optional config\n\n- wiring mocker connector into main mocker class\n\n- a single interface to interact with local and remote mocker\n\n- packaging existing mocker-db api routes with latest search options\n</code></pre>"},{"location":"release-notes/#024","title":"0.2.4","text":"<pre><code>- making hnswlib optional dependency\n</code></pre>"},{"location":"release-notes/#023","title":"0.2.3","text":"<pre><code>- providing flag to disable embedder initialization\n\n- disabling old cli intefrace\n\n- removing sentence_transformers from the list of default requirements so that SentenceTransformer needs to be provided externally if needed\n</code></pre>"},{"location":"release-notes/#022","title":"0.2.2","text":"<pre><code>- option to get embedded field\n\n- initial llm filter\n</code></pre>"},{"location":"release-notes/#021","title":"0.2.1","text":"<pre><code>- ability to return unique hash key for each record, previously inaccesible\n</code></pre>"},{"location":"release-notes/#020","title":"0.2.0","text":"<pre><code>- precise keywords match with cutoff 1 and fuzzy match with &lt; 1 through filters\n\n- keywords search with difflib\n</code></pre>"},{"location":"release-notes/#013","title":"0.1.3","text":"<pre><code>- option to add embedding and distance to output list\n\n- option to remove output key while outputting the rest of keys\n</code></pre>"},{"location":"release-notes/#012","title":"0.1.2","text":"<pre><code>- initital cli interface that allows to clone code from api version of mocker and run it\n</code></pre>"},{"location":"release-notes/#011","title":"0.1.1","text":"<pre><code>- initial MockerConnect for using MockerDB API\n</code></pre>"},{"location":"release-notes/#0012","title":"0.0.12","text":"<pre><code>-  bugfix for similarity search through partly embedded data\n</code></pre>"},{"location":"release-notes/#0011","title":"0.0.11","text":"<pre><code>- more advanced filtering\n</code></pre>"},{"location":"release-notes/#0010","title":"0.0.10","text":"<pre><code>- fix for search without embeddings\n</code></pre>"},{"location":"release-notes/#006","title":"0.0.6","text":"<pre><code>- fix for embedding storage\n</code></pre>"},{"location":"release-notes/#005","title":"0.0.5","text":"<pre><code>- initial implementation of separate caching store for embeddings\n</code></pre>"},{"location":"release-notes/#004","title":"0.0.4","text":"<pre><code>- updating hnswlib 0.7.0 -&gt; 0.8.0 to fix vulnerabilities issue\n\n- fixing a bug with resetting mocker inner state properly after search\n</code></pre>"},{"location":"release-notes/#003","title":"0.0.3","text":"<pre><code>- slightly improving logic of embedding with batches in parallel for sentence transformer embedder (default embedder)\n\n- updating desciption\n</code></pre>"},{"location":"release-notes/#002","title":"0.0.2","text":"<pre><code>- better error handling in situations when data was not found with applied filters\n</code></pre>"},{"location":"release-notes/#001","title":"0.0.1","text":"<pre><code>- initial version of MockerDB package that evolved from mock classes from redis into a standalone solution\n</code></pre>"}]}